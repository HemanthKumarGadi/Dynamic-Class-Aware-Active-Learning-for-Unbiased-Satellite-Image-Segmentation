{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbac3c-283f-429a-9766-853544831bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE LEARNING PIPELINE FOR SEMANTIC SEGMENTATION\n",
      "============================================================\n",
      "============================================================\n",
      "SYSTEM CAPABILITY CHECK\n",
      "============================================================\n",
      "Operating System: Windows 11\n",
      "Physical cores: 24\n",
      "Logical cores: 32\n",
      "Total RAM: 31.70 GB\n",
      "CUDA available: Yes, 1 GPU(s)\n",
      "Recommended num_workers: 0\n",
      "\n",
      "Using device: cuda\n",
      "GPU: NVIDIA RTX 4000 Ada Generation\n",
      "GPU Memory: 20.0 GB\n",
      "\n",
      "--- Data Verification ---\n",
      "Training: 512 images, 512 labels\n",
      "✓ Training: Data consistency verified\n",
      "Pool: 2414 images, 2414 labels\n",
      "✓ Pool: Data consistency verified\n",
      "Validation: 250 images, 250 labels\n",
      "✓ Validation: Data consistency verified\n",
      "Test: 250 images, 250 labels\n",
      "✓ Test: Data consistency verified\n",
      "\n",
      "--- Active Learning Configuration ---\n",
      "Max Iterations: 10\n",
      "Samples per Iteration: 100\n",
      "Epochs per Iteration: 80\n",
      "Batch Size: 8\n",
      "Learning Rate: 0.0001\n",
      "\n",
      "Validation samples: 250\n",
      "Test samples: 250\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 1/10\n",
      "============================================================\n",
      "Current training samples: 512\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.4063\n",
      "  Bareland: 0.7718\n",
      "  Rangeland: 0.0549\n",
      "  Developed Space: 0.0630\n",
      "  Road: 0.1869\n",
      "  Tree: 0.0971\n",
      "  Water: 0.1121\n",
      "  Agriculture Land: 0.1809\n",
      "  Building: 0.1270\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6798, Val Acc: 0.3065, Val mIoU: 0.2103\n",
      "Epoch 2/80 - Train Loss: 1.4316, Val Acc: 0.4180, Val mIoU: 0.2781\n",
      "Epoch 3/80 - Train Loss: 1.3513, Val Acc: 0.4727, Val mIoU: 0.3312\n",
      "Epoch 4/80 - Train Loss: 1.3239, Val Acc: 0.4494, Val mIoU: 0.2820\n",
      "Epoch 5/80 - Train Loss: 1.2855, Val Acc: 0.4860, Val mIoU: 0.3398\n",
      "Epoch 6/80 - Train Loss: 1.2556, Val Acc: 0.4953, Val mIoU: 0.3663\n",
      "Epoch 7/80 - Train Loss: 1.2123, Val Acc: 0.5368, Val mIoU: 0.3530\n",
      "Epoch 8/80 - Train Loss: 1.1846, Val Acc: 0.4900, Val mIoU: 0.3485\n",
      "Epoch 9/80 - Train Loss: 1.1620, Val Acc: 0.5094, Val mIoU: 0.3166\n",
      "Epoch 10/80 - Train Loss: 1.1536, Val Acc: 0.5201, Val mIoU: 0.3786\n",
      "Epoch 15/80 - Train Loss: 1.0653, Val Acc: 0.5336, Val mIoU: 0.3657\n",
      "Epoch 20/80 - Train Loss: 0.9902, Val Acc: 0.5875, Val mIoU: 0.4062\n",
      "Epoch 25/80 - Train Loss: 0.9649, Val Acc: 0.5764, Val mIoU: 0.4082\n",
      "Epoch 30/80 - Train Loss: 0.8760, Val Acc: 0.5997, Val mIoU: 0.4235\n",
      "Epoch 35/80 - Train Loss: 0.8536, Val Acc: 0.5920, Val mIoU: 0.4371\n",
      "Epoch 40/80 - Train Loss: 0.8243, Val Acc: 0.5867, Val mIoU: 0.3784\n",
      "Epoch 45/80 - Train Loss: 0.7396, Val Acc: 0.6393, Val mIoU: 0.4916\n",
      "Epoch 50/80 - Train Loss: 0.7503, Val Acc: 0.6172, Val mIoU: 0.4878\n",
      "Epoch 55/80 - Train Loss: 0.7233, Val Acc: 0.6375, Val mIoU: 0.4539\n",
      "Epoch 60/80 - Train Loss: 0.6678, Val Acc: 0.6485, Val mIoU: 0.4793\n",
      "Epoch 65/80 - Train Loss: 0.6081, Val Acc: 0.6566, Val mIoU: 0.5264\n",
      "Epoch 70/80 - Train Loss: 0.6197, Val Acc: 0.6711, Val mIoU: 0.5143\n",
      "Epoch 75/80 - Train Loss: 0.5717, Val Acc: 0.6822, Val mIoU: 0.5183\n",
      "Epoch 80/80 - Train Loss: 0.5506, Val Acc: 0.6845, Val mIoU: 0.5279\n",
      "Training completed after 80 epochs\n",
      "Training completed in 13298.14 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_1\\model_iteration_1.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.7016\n",
      "Test mIoU: 0.5395\n",
      "Test Loss: 0.7916\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 1 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.2877, Weight=0.0882\n",
      "  Bareland: Gap=0.8410, Weight=0.1508\n",
      "  Rangeland: Gap=0.4828, Weight=0.1142\n",
      "  Developed Space: Gap=0.5566, Weight=0.1226\n",
      "  Road: Gap=0.5412, Weight=0.1209\n",
      "  Tree: Gap=0.2842, Weight=0.0876\n",
      "  Water: Gap=0.3011, Weight=0.0902\n",
      "  Agriculture Land: Gap=0.5955, Weight=0.1269\n",
      "  Building: Gap=0.3592, Weight=0.0985\n",
      "Available pool samples: 2414\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0713\n",
      "  σ(t) = 0.0270\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0848\n",
      "  Samples passing threshold: 735/2414\n",
      "Top 5 DCAU scores: [0.15815086662769318, 0.15736830234527588, 0.15649986267089844, 0.15625408291816711, 0.1551676243543625]\n",
      "✅ Moved: TrainArea_1480.tif (DCAU score: 0.1582)\n",
      "✅ Moved: TrainArea_3662.tif (DCAU score: 0.1574)\n",
      "✅ Moved: TrainArea_2246.tif (DCAU score: 0.1565)\n",
      "✅ Moved: TrainArea_2655.tif (DCAU score: 0.1563)\n",
      "✅ Moved: TrainArea_3680.tif (DCAU score: 0.1552)\n",
      "✅ Moved: TrainArea_2654.tif (DCAU score: 0.1531)\n",
      "✅ Moved: TrainArea_3250.tif (DCAU score: 0.1498)\n",
      "✅ Moved: TrainArea_2529.tif (DCAU score: 0.1494)\n",
      "✅ Moved: TrainArea_2326.tif (DCAU score: 0.1489)\n",
      "✅ Moved: TrainArea_3118.tif (DCAU score: 0.1477)\n",
      "✅ Moved: TrainArea_2759.tif (DCAU score: 0.1456)\n",
      "✅ Moved: TrainArea_2274.tif (DCAU score: 0.1450)\n",
      "✅ Moved: TrainArea_1496.tif (DCAU score: 0.1420)\n",
      "✅ Moved: TrainArea_1119.tif (DCAU score: 0.1407)\n",
      "✅ Moved: TrainArea_3314.tif (DCAU score: 0.1388)\n",
      "✅ Moved: TrainArea_1162.tif (DCAU score: 0.1359)\n",
      "✅ Moved: TrainArea_3112.tif (DCAU score: 0.1345)\n",
      "✅ Moved: TrainArea_1049.tif (DCAU score: 0.1336)\n",
      "✅ Moved: TrainArea_3659.tif (DCAU score: 0.1326)\n",
      "✅ Moved: TrainArea_3504.tif (DCAU score: 0.1307)\n",
      "✅ Moved: TrainArea_1196.tif (DCAU score: 0.1299)\n",
      "✅ Moved: TrainArea_2323.tif (DCAU score: 0.1298)\n",
      "✅ Moved: TrainArea_3307.tif (DCAU score: 0.1294)\n",
      "✅ Moved: TrainArea_2225.tif (DCAU score: 0.1272)\n",
      "✅ Moved: TrainArea_2518.tif (DCAU score: 0.1270)\n",
      "✅ Moved: TrainArea_2972.tif (DCAU score: 0.1263)\n",
      "✅ Moved: TrainArea_2118.tif (DCAU score: 0.1250)\n",
      "✅ Moved: TrainArea_3438.tif (DCAU score: 0.1250)\n",
      "✅ Moved: TrainArea_1732.tif (DCAU score: 0.1244)\n",
      "✅ Moved: TrainArea_1700.tif (DCAU score: 0.1243)\n",
      "✅ Moved: TrainArea_3134.tif (DCAU score: 0.1238)\n",
      "✅ Moved: TrainArea_1276.tif (DCAU score: 0.1226)\n",
      "✅ Moved: TrainArea_2094.tif (DCAU score: 0.1222)\n",
      "✅ Moved: TrainArea_3283.tif (DCAU score: 0.1219)\n",
      "✅ Moved: TrainArea_2546.tif (DCAU score: 0.1217)\n",
      "✅ Moved: TrainArea_1542.tif (DCAU score: 0.1215)\n",
      "✅ Moved: TrainArea_2830.tif (DCAU score: 0.1215)\n",
      "✅ Moved: TrainArea_2429.tif (DCAU score: 0.1212)\n",
      "✅ Moved: TrainArea_1426.tif (DCAU score: 0.1211)\n",
      "✅ Moved: TrainArea_2871.tif (DCAU score: 0.1203)\n",
      "✅ Moved: TrainArea_1019.tif (DCAU score: 0.1199)\n",
      "✅ Moved: TrainArea_3048.tif (DCAU score: 0.1194)\n",
      "✅ Moved: TrainArea_1153.tif (DCAU score: 0.1194)\n",
      "✅ Moved: TrainArea_2641.tif (DCAU score: 0.1193)\n",
      "✅ Moved: TrainArea_3354.tif (DCAU score: 0.1193)\n",
      "✅ Moved: TrainArea_1779.tif (DCAU score: 0.1193)\n",
      "✅ Moved: TrainArea_3673.tif (DCAU score: 0.1186)\n",
      "✅ Moved: TrainArea_2890.tif (DCAU score: 0.1184)\n",
      "✅ Moved: TrainArea_2141.tif (DCAU score: 0.1182)\n",
      "✅ Moved: TrainArea_1185.tif (DCAU score: 0.1178)\n",
      "✅ Moved: TrainArea_2140.tif (DCAU score: 0.1172)\n",
      "✅ Moved: TrainArea_2021.tif (DCAU score: 0.1170)\n",
      "✅ Moved: TrainArea_2963.tif (DCAU score: 0.1164)\n",
      "✅ Moved: TrainArea_2693.tif (DCAU score: 0.1163)\n",
      "✅ Moved: TrainArea_2073.tif (DCAU score: 0.1162)\n",
      "✅ Moved: TrainArea_1977.tif (DCAU score: 0.1160)\n",
      "✅ Moved: TrainArea_2222.tif (DCAU score: 0.1157)\n",
      "✅ Moved: TrainArea_2390.tif (DCAU score: 0.1156)\n",
      "✅ Moved: TrainArea_1192.tif (DCAU score: 0.1154)\n",
      "✅ Moved: TrainArea_1962.tif (DCAU score: 0.1151)\n",
      "✅ Moved: TrainArea_3683.tif (DCAU score: 0.1148)\n",
      "✅ Moved: TrainArea_1905.tif (DCAU score: 0.1145)\n",
      "✅ Moved: TrainArea_1273.tif (DCAU score: 0.1144)\n",
      "✅ Moved: TrainArea_3468.tif (DCAU score: 0.1143)\n",
      "✅ Moved: TrainArea_3559.tif (DCAU score: 0.1143)\n",
      "✅ Moved: TrainArea_2833.tif (DCAU score: 0.1142)\n",
      "✅ Moved: TrainArea_1612.tif (DCAU score: 0.1142)\n",
      "✅ Moved: TrainArea_2111.tif (DCAU score: 0.1140)\n",
      "✅ Moved: TrainArea_2074.tif (DCAU score: 0.1139)\n",
      "✅ Moved: TrainArea_3562.tif (DCAU score: 0.1138)\n",
      "✅ Moved: TrainArea_2229.tif (DCAU score: 0.1137)\n",
      "✅ Moved: TrainArea_2236.tif (DCAU score: 0.1137)\n",
      "✅ Moved: TrainArea_3402.tif (DCAU score: 0.1136)\n",
      "✅ Moved: TrainArea_2780.tif (DCAU score: 0.1133)\n",
      "✅ Moved: TrainArea_2609.tif (DCAU score: 0.1129)\n",
      "✅ Moved: TrainArea_1593.tif (DCAU score: 0.1129)\n",
      "✅ Moved: TrainArea_2209.tif (DCAU score: 0.1128)\n",
      "✅ Moved: TrainArea_2218.tif (DCAU score: 0.1126)\n",
      "✅ Moved: TrainArea_1685.tif (DCAU score: 0.1125)\n",
      "✅ Moved: TrainArea_1647.tif (DCAU score: 0.1125)\n",
      "✅ Moved: TrainArea_2235.tif (DCAU score: 0.1124)\n",
      "✅ Moved: TrainArea_2607.tif (DCAU score: 0.1121)\n",
      "✅ Moved: TrainArea_2421.tif (DCAU score: 0.1119)\n",
      "✅ Moved: TrainArea_1881.tif (DCAU score: 0.1118)\n",
      "✅ Moved: TrainArea_2154.tif (DCAU score: 0.1118)\n",
      "✅ Moved: TrainArea_2974.tif (DCAU score: 0.1117)\n",
      "✅ Moved: TrainArea_3656.tif (DCAU score: 0.1117)\n",
      "✅ Moved: TrainArea_1312.tif (DCAU score: 0.1116)\n",
      "✅ Moved: TrainArea_3573.tif (DCAU score: 0.1115)\n",
      "✅ Moved: TrainArea_1900.tif (DCAU score: 0.1113)\n",
      "✅ Moved: TrainArea_2331.tif (DCAU score: 0.1111)\n",
      "✅ Moved: TrainArea_2300.tif (DCAU score: 0.1111)\n",
      "✅ Moved: TrainArea_3047.tif (DCAU score: 0.1110)\n",
      "✅ Moved: TrainArea_2911.tif (DCAU score: 0.1107)\n",
      "✅ Moved: TrainArea_1076.tif (DCAU score: 0.1107)\n",
      "✅ Moved: TrainArea_2660.tif (DCAU score: 0.1106)\n",
      "✅ Moved: TrainArea_2959.tif (DCAU score: 0.1106)\n",
      "✅ Moved: TrainArea_3340.tif (DCAU score: 0.1105)\n",
      "✅ Moved: TrainArea_1948.tif (DCAU score: 0.1104)\n",
      "✅ Moved: TrainArea_1350.tif (DCAU score: 0.1102)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_1\\selected_samples\\dcau_gamma_selection_log_iteration_1.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0848\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 2314\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 1 Complete ---\n",
      "Training samples: 512\n",
      "Validation Accuracy: 0.6845\n",
      "Test Accuracy: 0.7016\n",
      "Test mIoU: 0.5395\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 2/10\n",
      "============================================================\n",
      "Current training samples: 612\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.5939\n",
      "  Bareland: 0.6117\n",
      "  Rangeland: 0.0532\n",
      "  Developed Space: 0.0526\n",
      "  Road: 0.1855\n",
      "  Tree: 0.1065\n",
      "  Water: 0.1163\n",
      "  Agriculture Land: 0.1459\n",
      "  Building: 0.1343\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6824, Val Acc: 0.3937, Val mIoU: 0.2297\n",
      "Epoch 2/80 - Train Loss: 1.4405, Val Acc: 0.4427, Val mIoU: 0.2358\n",
      "Epoch 3/80 - Train Loss: 1.3770, Val Acc: 0.4206, Val mIoU: 0.2432\n",
      "Epoch 4/80 - Train Loss: 1.3421, Val Acc: 0.4949, Val mIoU: 0.3172\n",
      "Epoch 5/80 - Train Loss: 1.3208, Val Acc: 0.4806, Val mIoU: 0.3060\n",
      "Epoch 6/80 - Train Loss: 1.2832, Val Acc: 0.4892, Val mIoU: 0.3786\n",
      "Epoch 7/80 - Train Loss: 1.2664, Val Acc: 0.4806, Val mIoU: 0.3367\n",
      "Epoch 8/80 - Train Loss: 1.2574, Val Acc: 0.4878, Val mIoU: 0.3081\n",
      "Epoch 9/80 - Train Loss: 1.1981, Val Acc: 0.5248, Val mIoU: 0.3536\n",
      "Epoch 10/80 - Train Loss: 1.1879, Val Acc: 0.5157, Val mIoU: 0.3609\n",
      "Epoch 15/80 - Train Loss: 1.1365, Val Acc: 0.5120, Val mIoU: 0.3670\n",
      "Epoch 20/80 - Train Loss: 1.0486, Val Acc: 0.5449, Val mIoU: 0.3767\n",
      "Epoch 25/80 - Train Loss: 1.0074, Val Acc: 0.5906, Val mIoU: 0.3858\n",
      "Epoch 30/80 - Train Loss: 0.9379, Val Acc: 0.6108, Val mIoU: 0.4695\n",
      "Epoch 35/80 - Train Loss: 0.8995, Val Acc: 0.5974, Val mIoU: 0.4808\n",
      "Epoch 40/80 - Train Loss: 0.8654, Val Acc: 0.5913, Val mIoU: 0.4135\n",
      "Epoch 45/80 - Train Loss: 0.7973, Val Acc: 0.6269, Val mIoU: 0.4958\n",
      "Epoch 50/80 - Train Loss: 0.7922, Val Acc: 0.6286, Val mIoU: 0.4915\n",
      "Epoch 55/80 - Train Loss: 0.7522, Val Acc: 0.6346, Val mIoU: 0.4676\n",
      "Epoch 60/80 - Train Loss: 0.6866, Val Acc: 0.6705, Val mIoU: 0.5237\n",
      "Epoch 65/80 - Train Loss: 0.6749, Val Acc: 0.6595, Val mIoU: 0.5274\n",
      "Epoch 70/80 - Train Loss: 0.6160, Val Acc: 0.6582, Val mIoU: 0.5321\n",
      "Epoch 75/80 - Train Loss: 0.5659, Val Acc: 0.6870, Val mIoU: 0.5488\n",
      "Epoch 80/80 - Train Loss: 0.5688, Val Acc: 0.6739, Val mIoU: 0.5293\n",
      "Training completed after 80 epochs\n",
      "Training completed in 14114.98 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_2\\model_iteration_2.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.6888\n",
      "Test mIoU: 0.5277\n",
      "Test Loss: 0.7904\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 2 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.2507, Weight=0.0826\n",
      "  Bareland: Gap=0.8291, Weight=0.1502\n",
      "  Rangeland: Gap=0.5100, Weight=0.1178\n",
      "  Developed Space: Gap=0.5931, Weight=0.1270\n",
      "  Road: Gap=0.5680, Weight=0.1243\n",
      "  Tree: Gap=0.2958, Weight=0.0897\n",
      "  Water: Gap=0.2780, Weight=0.0869\n",
      "  Agriculture Land: Gap=0.5442, Weight=0.1217\n",
      "  Building: Gap=0.3673, Weight=0.0999\n",
      "Available pool samples: 2314\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0710\n",
      "  σ(t) = 0.0259\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0839\n",
      "  Samples passing threshold: 800/2314\n",
      "Top 5 DCAU scores: [0.1288062036037445, 0.12452004104852676, 0.12392700463533401, 0.12061760574579239, 0.12000191956758499]\n",
      "✅ Moved: TrainArea_1622.tif (DCAU score: 0.1288)\n",
      "✅ Moved: TrainArea_1294.tif (DCAU score: 0.1245)\n",
      "✅ Moved: TrainArea_2517.tif (DCAU score: 0.1239)\n",
      "✅ Moved: TrainArea_1140.tif (DCAU score: 0.1206)\n",
      "✅ Moved: TrainArea_3665.tif (DCAU score: 0.1200)\n",
      "✅ Moved: TrainArea_2674.tif (DCAU score: 0.1198)\n",
      "✅ Moved: TrainArea_2138.tif (DCAU score: 0.1196)\n",
      "✅ Moved: TrainArea_2108.tif (DCAU score: 0.1156)\n",
      "✅ Moved: TrainArea_2196.tif (DCAU score: 0.1153)\n",
      "✅ Moved: TrainArea_1340.tif (DCAU score: 0.1151)\n",
      "✅ Moved: TrainArea_3664.tif (DCAU score: 0.1150)\n",
      "✅ Moved: TrainArea_2414.tif (DCAU score: 0.1149)\n",
      "✅ Moved: TrainArea_2585.tif (DCAU score: 0.1147)\n",
      "✅ Moved: TrainArea_1223.tif (DCAU score: 0.1142)\n",
      "✅ Moved: TrainArea_3584.tif (DCAU score: 0.1135)\n",
      "✅ Moved: TrainArea_2560.tif (DCAU score: 0.1135)\n",
      "✅ Moved: TrainArea_2378.tif (DCAU score: 0.1135)\n",
      "✅ Moved: TrainArea_2985.tif (DCAU score: 0.1134)\n",
      "✅ Moved: TrainArea_1730.tif (DCAU score: 0.1134)\n",
      "✅ Moved: TrainArea_1069.tif (DCAU score: 0.1133)\n",
      "✅ Moved: TrainArea_1258.tif (DCAU score: 0.1130)\n",
      "✅ Moved: TrainArea_2060.tif (DCAU score: 0.1129)\n",
      "✅ Moved: TrainArea_1026.tif (DCAU score: 0.1121)\n",
      "✅ Moved: TrainArea_2104.tif (DCAU score: 0.1119)\n",
      "✅ Moved: TrainArea_2766.tif (DCAU score: 0.1115)\n",
      "✅ Moved: TrainArea_2782.tif (DCAU score: 0.1111)\n",
      "✅ Moved: TrainArea_1972.tif (DCAU score: 0.1108)\n",
      "✅ Moved: TrainArea_2588.tif (DCAU score: 0.1106)\n",
      "✅ Moved: TrainArea_2334.tif (DCAU score: 0.1104)\n",
      "✅ Moved: TrainArea_2367.tif (DCAU score: 0.1100)\n",
      "✅ Moved: TrainArea_3578.tif (DCAU score: 0.1095)\n",
      "✅ Moved: TrainArea_3458.tif (DCAU score: 0.1093)\n",
      "✅ Moved: TrainArea_3535.tif (DCAU score: 0.1092)\n",
      "✅ Moved: TrainArea_1338.tif (DCAU score: 0.1090)\n",
      "✅ Moved: TrainArea_2950.tif (DCAU score: 0.1090)\n",
      "✅ Moved: TrainArea_2705.tif (DCAU score: 0.1089)\n",
      "✅ Moved: TrainArea_2189.tif (DCAU score: 0.1089)\n",
      "✅ Moved: TrainArea_2931.tif (DCAU score: 0.1086)\n",
      "✅ Moved: TrainArea_3372.tif (DCAU score: 0.1085)\n",
      "✅ Moved: TrainArea_2510.tif (DCAU score: 0.1084)\n",
      "✅ Moved: TrainArea_3648.tif (DCAU score: 0.1083)\n",
      "✅ Moved: TrainArea_3556.tif (DCAU score: 0.1082)\n",
      "✅ Moved: TrainArea_2278.tif (DCAU score: 0.1080)\n",
      "✅ Moved: TrainArea_2548.tif (DCAU score: 0.1079)\n",
      "✅ Moved: TrainArea_2488.tif (DCAU score: 0.1077)\n",
      "✅ Moved: TrainArea_3690.tif (DCAU score: 0.1077)\n",
      "✅ Moved: TrainArea_3149.tif (DCAU score: 0.1076)\n",
      "✅ Moved: TrainArea_2547.tif (DCAU score: 0.1076)\n",
      "✅ Moved: TrainArea_3687.tif (DCAU score: 0.1075)\n",
      "✅ Moved: TrainArea_2182.tif (DCAU score: 0.1074)\n",
      "✅ Moved: TrainArea_1774.tif (DCAU score: 0.1073)\n",
      "✅ Moved: TrainArea_2435.tif (DCAU score: 0.1073)\n",
      "✅ Moved: TrainArea_1095.tif (DCAU score: 0.1072)\n",
      "✅ Moved: TrainArea_2318.tif (DCAU score: 0.1071)\n",
      "✅ Moved: TrainArea_3700.tif (DCAU score: 0.1071)\n",
      "✅ Moved: TrainArea_1694.tif (DCAU score: 0.1070)\n",
      "✅ Moved: TrainArea_3369.tif (DCAU score: 0.1069)\n",
      "✅ Moved: TrainArea_1723.tif (DCAU score: 0.1069)\n",
      "✅ Moved: TrainArea_1229.tif (DCAU score: 0.1068)\n",
      "✅ Moved: TrainArea_1764.tif (DCAU score: 0.1068)\n",
      "✅ Moved: TrainArea_3691.tif (DCAU score: 0.1065)\n",
      "✅ Moved: TrainArea_1232.tif (DCAU score: 0.1065)\n",
      "✅ Moved: TrainArea_1957.tif (DCAU score: 0.1065)\n",
      "✅ Moved: TrainArea_1067.tif (DCAU score: 0.1064)\n",
      "✅ Moved: TrainArea_3586.tif (DCAU score: 0.1063)\n",
      "✅ Moved: TrainArea_2977.tif (DCAU score: 0.1063)\n",
      "✅ Moved: TrainArea_3133.tif (DCAU score: 0.1062)\n",
      "✅ Moved: TrainArea_2462.tif (DCAU score: 0.1062)\n",
      "✅ Moved: TrainArea_1689.tif (DCAU score: 0.1061)\n",
      "✅ Moved: TrainArea_1124.tif (DCAU score: 0.1060)\n",
      "✅ Moved: TrainArea_2608.tif (DCAU score: 0.1058)\n",
      "✅ Moved: TrainArea_2704.tif (DCAU score: 0.1057)\n",
      "✅ Moved: TrainArea_1714.tif (DCAU score: 0.1055)\n",
      "✅ Moved: TrainArea_1807.tif (DCAU score: 0.1054)\n",
      "✅ Moved: TrainArea_2126.tif (DCAU score: 0.1053)\n",
      "✅ Moved: TrainArea_3287.tif (DCAU score: 0.1053)\n",
      "✅ Moved: TrainArea_2679.tif (DCAU score: 0.1052)\n",
      "✅ Moved: TrainArea_3245.tif (DCAU score: 0.1052)\n",
      "✅ Moved: TrainArea_2786.tif (DCAU score: 0.1051)\n",
      "✅ Moved: TrainArea_3590.tif (DCAU score: 0.1051)\n",
      "✅ Moved: TrainArea_2217.tif (DCAU score: 0.1050)\n",
      "✅ Moved: TrainArea_1718.tif (DCAU score: 0.1049)\n",
      "✅ Moved: TrainArea_3018.tif (DCAU score: 0.1048)\n",
      "✅ Moved: TrainArea_1262.tif (DCAU score: 0.1047)\n",
      "✅ Moved: TrainArea_3086.tif (DCAU score: 0.1046)\n",
      "✅ Moved: TrainArea_3242.tif (DCAU score: 0.1046)\n",
      "✅ Moved: TrainArea_3427.tif (DCAU score: 0.1046)\n",
      "✅ Moved: TrainArea_2897.tif (DCAU score: 0.1045)\n",
      "✅ Moved: TrainArea_1585.tif (DCAU score: 0.1045)\n",
      "✅ Moved: TrainArea_2251.tif (DCAU score: 0.1044)\n",
      "✅ Moved: TrainArea_1788.tif (DCAU score: 0.1044)\n",
      "✅ Moved: TrainArea_3064.tif (DCAU score: 0.1043)\n",
      "✅ Moved: TrainArea_2375.tif (DCAU score: 0.1042)\n",
      "✅ Moved: TrainArea_3162.tif (DCAU score: 0.1041)\n",
      "✅ Moved: TrainArea_2593.tif (DCAU score: 0.1041)\n",
      "✅ Moved: TrainArea_2511.tif (DCAU score: 0.1038)\n",
      "✅ Moved: TrainArea_3474.tif (DCAU score: 0.1037)\n",
      "✅ Moved: TrainArea_1772.tif (DCAU score: 0.1037)\n",
      "✅ Moved: TrainArea_2450.tif (DCAU score: 0.1037)\n",
      "✅ Moved: TrainArea_1705.tif (DCAU score: 0.1036)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_2\\selected_samples\\dcau_gamma_selection_log_iteration_2.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0839\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 2214\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 2 Complete ---\n",
      "Training samples: 612\n",
      "Validation Accuracy: 0.6739\n",
      "Test Accuracy: 0.6888\n",
      "Test mIoU: 0.5277\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 3/10\n",
      "============================================================\n",
      "Current training samples: 712\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.3504\n",
      "  Bareland: 0.7454\n",
      "  Rangeland: 0.0597\n",
      "  Developed Space: 0.0555\n",
      "  Road: 0.2069\n",
      "  Tree: 0.1272\n",
      "  Water: 0.1468\n",
      "  Agriculture Land: 0.1626\n",
      "  Building: 0.1454\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.7068, Val Acc: 0.3791, Val mIoU: 0.2619\n",
      "Epoch 2/80 - Train Loss: 1.4561, Val Acc: 0.4484, Val mIoU: 0.3083\n",
      "Epoch 3/80 - Train Loss: 1.3957, Val Acc: 0.4503, Val mIoU: 0.3449\n",
      "Epoch 4/80 - Train Loss: 1.3376, Val Acc: 0.4814, Val mIoU: 0.3398\n",
      "Epoch 5/80 - Train Loss: 1.3356, Val Acc: 0.5146, Val mIoU: 0.3637\n",
      "Epoch 6/80 - Train Loss: 1.3002, Val Acc: 0.4784, Val mIoU: 0.3737\n",
      "Epoch 7/80 - Train Loss: 1.2659, Val Acc: 0.5131, Val mIoU: 0.3943\n",
      "Epoch 8/80 - Train Loss: 1.2700, Val Acc: 0.5215, Val mIoU: 0.4011\n",
      "Epoch 9/80 - Train Loss: 1.1909, Val Acc: 0.5242, Val mIoU: 0.4194\n",
      "Epoch 10/80 - Train Loss: 1.2041, Val Acc: 0.5337, Val mIoU: 0.4062\n",
      "Epoch 15/80 - Train Loss: 1.1301, Val Acc: 0.5592, Val mIoU: 0.3910\n",
      "Epoch 20/80 - Train Loss: 1.0333, Val Acc: 0.5687, Val mIoU: 0.4508\n",
      "Epoch 25/80 - Train Loss: 0.9792, Val Acc: 0.6321, Val mIoU: 0.5001\n",
      "Epoch 30/80 - Train Loss: 0.9299, Val Acc: 0.6186, Val mIoU: 0.4772\n",
      "Epoch 35/80 - Train Loss: 0.8920, Val Acc: 0.5907, Val mIoU: 0.4370\n",
      "Epoch 40/80 - Train Loss: 0.8719, Val Acc: 0.6587, Val mIoU: 0.5181\n",
      "Epoch 45/80 - Train Loss: 0.8060, Val Acc: 0.6386, Val mIoU: 0.4951\n",
      "Epoch 50/80 - Train Loss: 0.7608, Val Acc: 0.6514, Val mIoU: 0.5167\n",
      "Epoch 55/80 - Train Loss: 0.7306, Val Acc: 0.6434, Val mIoU: 0.5158\n",
      "Epoch 60/80 - Train Loss: 0.6592, Val Acc: 0.6400, Val mIoU: 0.5176\n",
      "Epoch 65/80 - Train Loss: 0.6428, Val Acc: 0.6503, Val mIoU: 0.5164\n",
      "Epoch 70/80 - Train Loss: 0.5919, Val Acc: 0.6738, Val mIoU: 0.5090\n",
      "Epoch 75/80 - Train Loss: 0.5905, Val Acc: 0.6863, Val mIoU: 0.5459\n",
      "Epoch 80/80 - Train Loss: 0.5601, Val Acc: 0.6933, Val mIoU: 0.5549\n",
      "Training completed after 80 epochs\n",
      "Training completed in 14885.69 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_3\\model_iteration_3.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.7080\n",
      "Test mIoU: 0.5695\n",
      "Test Loss: 0.7665\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 3 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.1487, Weight=0.0658\n",
      "  Bareland: Gap=0.8428, Weight=0.1567\n",
      "  Rangeland: Gap=0.4817, Weight=0.1184\n",
      "  Developed Space: Gap=0.5441, Weight=0.1259\n",
      "  Road: Gap=0.5386, Weight=0.1252\n",
      "  Tree: Gap=0.3017, Weight=0.0937\n",
      "  Water: Gap=0.2765, Weight=0.0897\n",
      "  Agriculture Land: Gap=0.5097, Weight=0.1218\n",
      "  Building: Gap=0.3620, Weight=0.1027\n",
      "Available pool samples: 2214\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0681\n",
      "  σ(t) = 0.0238\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0801\n",
      "  Samples passing threshold: 723/2214\n",
      "Top 5 DCAU scores: [0.1353718340396881, 0.1326567828655243, 0.12627792358398438, 0.12501311302185059, 0.12456569075584412]\n",
      "✅ Moved: TrainArea_1035.tif (DCAU score: 0.1354)\n",
      "✅ Moved: TrainArea_1939.tif (DCAU score: 0.1327)\n",
      "✅ Moved: TrainArea_2045.tif (DCAU score: 0.1263)\n",
      "✅ Moved: TrainArea_2628.tif (DCAU score: 0.1250)\n",
      "✅ Moved: TrainArea_2537.tif (DCAU score: 0.1246)\n",
      "✅ Moved: TrainArea_3682.tif (DCAU score: 0.1246)\n",
      "✅ Moved: TrainArea_2256.tif (DCAU score: 0.1229)\n",
      "✅ Moved: TrainArea_2459.tif (DCAU score: 0.1223)\n",
      "✅ Moved: TrainArea_2555.tif (DCAU score: 0.1223)\n",
      "✅ Moved: TrainArea_2987.tif (DCAU score: 0.1191)\n",
      "✅ Moved: TrainArea_3331.tif (DCAU score: 0.1184)\n",
      "✅ Moved: TrainArea_2988.tif (DCAU score: 0.1180)\n",
      "✅ Moved: TrainArea_2753.tif (DCAU score: 0.1173)\n",
      "✅ Moved: TrainArea_1492.tif (DCAU score: 0.1163)\n",
      "✅ Moved: TrainArea_2169.tif (DCAU score: 0.1158)\n",
      "✅ Moved: TrainArea_2333.tif (DCAU score: 0.1147)\n",
      "✅ Moved: TrainArea_3434.tif (DCAU score: 0.1145)\n",
      "✅ Moved: TrainArea_2564.tif (DCAU score: 0.1141)\n",
      "✅ Moved: TrainArea_1971.tif (DCAU score: 0.1140)\n",
      "✅ Moved: TrainArea_3145.tif (DCAU score: 0.1135)\n",
      "✅ Moved: TrainArea_2935.tif (DCAU score: 0.1134)\n",
      "✅ Moved: TrainArea_3496.tif (DCAU score: 0.1128)\n",
      "✅ Moved: TrainArea_3158.tif (DCAU score: 0.1127)\n",
      "✅ Moved: TrainArea_3163.tif (DCAU score: 0.1115)\n",
      "✅ Moved: TrainArea_3240.tif (DCAU score: 0.1103)\n",
      "✅ Moved: TrainArea_2626.tif (DCAU score: 0.1102)\n",
      "✅ Moved: TrainArea_1414.tif (DCAU score: 0.1090)\n",
      "✅ Moved: TrainArea_1178.tif (DCAU score: 0.1087)\n",
      "✅ Moved: TrainArea_1272.tif (DCAU score: 0.1086)\n",
      "✅ Moved: TrainArea_2083.tif (DCAU score: 0.1080)\n",
      "✅ Moved: TrainArea_3137.tif (DCAU score: 0.1079)\n",
      "✅ Moved: TrainArea_3009.tif (DCAU score: 0.1077)\n",
      "✅ Moved: TrainArea_3539.tif (DCAU score: 0.1074)\n",
      "✅ Moved: TrainArea_3670.tif (DCAU score: 0.1070)\n",
      "✅ Moved: TrainArea_3311.tif (DCAU score: 0.1070)\n",
      "✅ Moved: TrainArea_1471.tif (DCAU score: 0.1069)\n",
      "✅ Moved: TrainArea_2153.tif (DCAU score: 0.1069)\n",
      "✅ Moved: TrainArea_1707.tif (DCAU score: 0.1067)\n",
      "✅ Moved: TrainArea_1224.tif (DCAU score: 0.1066)\n",
      "✅ Moved: TrainArea_1126.tif (DCAU score: 0.1066)\n",
      "✅ Moved: TrainArea_2697.tif (DCAU score: 0.1063)\n",
      "✅ Moved: TrainArea_2483.tif (DCAU score: 0.1063)\n",
      "✅ Moved: TrainArea_2098.tif (DCAU score: 0.1061)\n",
      "✅ Moved: TrainArea_2498.tif (DCAU score: 0.1061)\n",
      "✅ Moved: TrainArea_1870.tif (DCAU score: 0.1061)\n",
      "✅ Moved: TrainArea_1875.tif (DCAU score: 0.1058)\n",
      "✅ Moved: TrainArea_1121.tif (DCAU score: 0.1056)\n",
      "✅ Moved: TrainArea_3290.tif (DCAU score: 0.1055)\n",
      "✅ Moved: TrainArea_1944.tif (DCAU score: 0.1054)\n",
      "✅ Moved: TrainArea_2568.tif (DCAU score: 0.1052)\n",
      "✅ Moved: TrainArea_2146.tif (DCAU score: 0.1052)\n",
      "✅ Moved: TrainArea_2894.tif (DCAU score: 0.1051)\n",
      "✅ Moved: TrainArea_3004.tif (DCAU score: 0.1049)\n",
      "✅ Moved: TrainArea_2960.tif (DCAU score: 0.1048)\n",
      "✅ Moved: TrainArea_3357.tif (DCAU score: 0.1045)\n",
      "✅ Moved: TrainArea_3460.tif (DCAU score: 0.1045)\n",
      "✅ Moved: TrainArea_2603.tif (DCAU score: 0.1044)\n",
      "✅ Moved: TrainArea_1307.tif (DCAU score: 0.1044)\n",
      "✅ Moved: TrainArea_2115.tif (DCAU score: 0.1043)\n",
      "✅ Moved: TrainArea_2290.tif (DCAU score: 0.1042)\n",
      "✅ Moved: TrainArea_1798.tif (DCAU score: 0.1037)\n",
      "✅ Moved: TrainArea_1693.tif (DCAU score: 0.1036)\n",
      "✅ Moved: TrainArea_2068.tif (DCAU score: 0.1034)\n",
      "✅ Moved: TrainArea_3650.tif (DCAU score: 0.1031)\n",
      "✅ Moved: TrainArea_3540.tif (DCAU score: 0.1031)\n",
      "✅ Moved: TrainArea_2730.tif (DCAU score: 0.1030)\n",
      "✅ Moved: TrainArea_3591.tif (DCAU score: 0.1030)\n",
      "✅ Moved: TrainArea_3066.tif (DCAU score: 0.1030)\n",
      "✅ Moved: TrainArea_1423.tif (DCAU score: 0.1029)\n",
      "✅ Moved: TrainArea_1725.tif (DCAU score: 0.1029)\n",
      "✅ Moved: TrainArea_1747.tif (DCAU score: 0.1029)\n",
      "✅ Moved: TrainArea_2856.tif (DCAU score: 0.1028)\n",
      "✅ Moved: TrainArea_1060.tif (DCAU score: 0.1028)\n",
      "✅ Moved: TrainArea_3674.tif (DCAU score: 0.1027)\n",
      "✅ Moved: TrainArea_2820.tif (DCAU score: 0.1027)\n",
      "✅ Moved: TrainArea_3169.tif (DCAU score: 0.1025)\n",
      "✅ Moved: TrainArea_2092.tif (DCAU score: 0.1024)\n",
      "✅ Moved: TrainArea_1884.tif (DCAU score: 0.1023)\n",
      "✅ Moved: TrainArea_2846.tif (DCAU score: 0.1022)\n",
      "✅ Moved: TrainArea_3485.tif (DCAU score: 0.1021)\n",
      "✅ Moved: TrainArea_3143.tif (DCAU score: 0.1021)\n",
      "✅ Moved: TrainArea_1887.tif (DCAU score: 0.1019)\n",
      "✅ Moved: TrainArea_1473.tif (DCAU score: 0.1017)\n",
      "✅ Moved: TrainArea_3528.tif (DCAU score: 0.1017)\n",
      "✅ Moved: TrainArea_1663.tif (DCAU score: 0.1017)\n",
      "✅ Moved: TrainArea_1564.tif (DCAU score: 0.1016)\n",
      "✅ Moved: TrainArea_1631.tif (DCAU score: 0.1016)\n",
      "✅ Moved: TrainArea_2405.tif (DCAU score: 0.1015)\n",
      "✅ Moved: TrainArea_3020.tif (DCAU score: 0.1012)\n",
      "✅ Moved: TrainArea_1793.tif (DCAU score: 0.1012)\n",
      "✅ Moved: TrainArea_2810.tif (DCAU score: 0.1011)\n",
      "✅ Moved: TrainArea_3115.tif (DCAU score: 0.1010)\n",
      "✅ Moved: TrainArea_3192.tif (DCAU score: 0.1009)\n",
      "✅ Moved: TrainArea_2948.tif (DCAU score: 0.1009)\n",
      "✅ Moved: TrainArea_1348.tif (DCAU score: 0.1008)\n",
      "✅ Moved: TrainArea_3114.tif (DCAU score: 0.1006)\n",
      "✅ Moved: TrainArea_1576.tif (DCAU score: 0.1005)\n",
      "✅ Moved: TrainArea_1380.tif (DCAU score: 0.1004)\n",
      "✅ Moved: TrainArea_2971.tif (DCAU score: 0.1004)\n",
      "✅ Moved: TrainArea_1528.tif (DCAU score: 0.1003)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_3\\selected_samples\\dcau_gamma_selection_log_iteration_3.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0801\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 2114\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 3 Complete ---\n",
      "Training samples: 712\n",
      "Validation Accuracy: 0.6933\n",
      "Test Accuracy: 0.7080\n",
      "Test mIoU: 0.5695\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 4/10\n",
      "============================================================\n",
      "Current training samples: 812\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.6504\n",
      "  Bareland: 0.4981\n",
      "  Rangeland: 0.0510\n",
      "  Developed Space: 0.0509\n",
      "  Road: 0.1865\n",
      "  Tree: 0.1244\n",
      "  Water: 0.1513\n",
      "  Agriculture Land: 0.1514\n",
      "  Building: 0.1358\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6716, Val Acc: 0.3807, Val mIoU: 0.2212\n",
      "Epoch 2/80 - Train Loss: 1.4863, Val Acc: 0.4336, Val mIoU: 0.2557\n",
      "Epoch 3/80 - Train Loss: 1.3865, Val Acc: 0.4671, Val mIoU: 0.3001\n",
      "Epoch 4/80 - Train Loss: 1.3551, Val Acc: 0.4661, Val mIoU: 0.3335\n",
      "Epoch 5/80 - Train Loss: 1.3213, Val Acc: 0.4867, Val mIoU: 0.3587\n",
      "Epoch 6/80 - Train Loss: 1.3103, Val Acc: 0.5016, Val mIoU: 0.3577\n",
      "Epoch 7/80 - Train Loss: 1.2542, Val Acc: 0.4747, Val mIoU: 0.2814\n",
      "Epoch 8/80 - Train Loss: 1.2606, Val Acc: 0.5466, Val mIoU: 0.3808\n",
      "Epoch 9/80 - Train Loss: 1.2329, Val Acc: 0.5185, Val mIoU: 0.3971\n",
      "Epoch 10/80 - Train Loss: 1.2184, Val Acc: 0.5515, Val mIoU: 0.4186\n",
      "Epoch 15/80 - Train Loss: 1.1382, Val Acc: 0.5654, Val mIoU: 0.4312\n",
      "Epoch 20/80 - Train Loss: 1.0601, Val Acc: 0.5855, Val mIoU: 0.4492\n",
      "Epoch 25/80 - Train Loss: 0.9841, Val Acc: 0.5827, Val mIoU: 0.4181\n",
      "Epoch 30/80 - Train Loss: 0.9206, Val Acc: 0.5914, Val mIoU: 0.4509\n",
      "Epoch 35/80 - Train Loss: 0.8885, Val Acc: 0.6397, Val mIoU: 0.5050\n",
      "Epoch 40/80 - Train Loss: 0.8009, Val Acc: 0.6714, Val mIoU: 0.5241\n",
      "Epoch 45/80 - Train Loss: 0.7868, Val Acc: 0.6556, Val mIoU: 0.5292\n",
      "Epoch 50/80 - Train Loss: 0.7145, Val Acc: 0.6698, Val mIoU: 0.5341\n",
      "Epoch 55/80 - Train Loss: 0.6722, Val Acc: 0.6734, Val mIoU: 0.5456\n",
      "Epoch 60/80 - Train Loss: 0.6306, Val Acc: 0.7013, Val mIoU: 0.5624\n",
      "Epoch 65/80 - Train Loss: 0.5638, Val Acc: 0.6896, Val mIoU: 0.5372\n",
      "Epoch 70/80 - Train Loss: 0.5274, Val Acc: 0.6885, Val mIoU: 0.5387\n",
      "Epoch 75/80 - Train Loss: 0.4959, Val Acc: 0.7201, Val mIoU: 0.5829\n",
      "Epoch 80/80 - Train Loss: 0.4326, Val Acc: 0.7184, Val mIoU: 0.5564\n",
      "Training completed after 80 epochs\n",
      "Training completed in 15765.31 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_4\\model_iteration_4.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.7352\n",
      "Test mIoU: 0.5507\n",
      "Test Loss: 0.7464\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 4 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.3905, Weight=0.1053\n",
      "  Bareland: Gap=0.6541, Weight=0.1363\n",
      "  Rangeland: Gap=0.4630, Weight=0.1147\n",
      "  Developed Space: Gap=0.5380, Weight=0.1237\n",
      "  Road: Gap=0.5315, Weight=0.1229\n",
      "  Tree: Gap=0.2749, Weight=0.0884\n",
      "  Water: Gap=0.2514, Weight=0.0845\n",
      "  Agriculture Land: Gap=0.5145, Weight=0.1209\n",
      "  Building: Gap=0.3746, Weight=0.1032\n",
      "Available pool samples: 2114\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0573\n",
      "  σ(t) = 0.0227\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0686\n",
      "  Samples passing threshold: 736/2114\n",
      "Top 5 DCAU scores: [0.12679219245910645, 0.12383219599723816, 0.12119385600090027, 0.12050129473209381, 0.12049074470996857]\n",
      "✅ Moved: TrainArea_2865.tif (DCAU score: 0.1268)\n",
      "✅ Moved: TrainArea_2695.tif (DCAU score: 0.1238)\n",
      "✅ Moved: TrainArea_3251.tif (DCAU score: 0.1212)\n",
      "✅ Moved: TrainArea_2554.tif (DCAU score: 0.1205)\n",
      "✅ Moved: TrainArea_1584.tif (DCAU score: 0.1205)\n",
      "✅ Moved: TrainArea_2847.tif (DCAU score: 0.1194)\n",
      "✅ Moved: TrainArea_1662.tif (DCAU score: 0.1161)\n",
      "✅ Moved: TrainArea_2992.tif (DCAU score: 0.1151)\n",
      "✅ Moved: TrainArea_1038.tif (DCAU score: 0.1151)\n",
      "✅ Moved: TrainArea_1540.tif (DCAU score: 0.1110)\n",
      "✅ Moved: TrainArea_1823.tif (DCAU score: 0.1096)\n",
      "✅ Moved: TrainArea_1623.tif (DCAU score: 0.1086)\n",
      "✅ Moved: TrainArea_3568.tif (DCAU score: 0.1084)\n",
      "✅ Moved: TrainArea_2027.tif (DCAU score: 0.1076)\n",
      "✅ Moved: TrainArea_1842.tif (DCAU score: 0.1071)\n",
      "✅ Moved: TrainArea_3296.tif (DCAU score: 0.1070)\n",
      "✅ Moved: TrainArea_1810.tif (DCAU score: 0.1060)\n",
      "✅ Moved: TrainArea_1407.tif (DCAU score: 0.1037)\n",
      "✅ Moved: TrainArea_3028.tif (DCAU score: 0.1028)\n",
      "✅ Moved: TrainArea_2566.tif (DCAU score: 0.1018)\n",
      "✅ Moved: TrainArea_1118.tif (DCAU score: 0.1011)\n",
      "✅ Moved: TrainArea_3696.tif (DCAU score: 0.1006)\n",
      "✅ Moved: TrainArea_2411.tif (DCAU score: 0.1002)\n",
      "✅ Moved: TrainArea_1596.tif (DCAU score: 0.0991)\n",
      "✅ Moved: TrainArea_1614.tif (DCAU score: 0.0988)\n",
      "✅ Moved: TrainArea_2918.tif (DCAU score: 0.0984)\n",
      "✅ Moved: TrainArea_1205.tif (DCAU score: 0.0982)\n",
      "✅ Moved: TrainArea_3480.tif (DCAU score: 0.0980)\n",
      "✅ Moved: TrainArea_3015.tif (DCAU score: 0.0965)\n",
      "✅ Moved: TrainArea_1254.tif (DCAU score: 0.0960)\n",
      "✅ Moved: TrainArea_1156.tif (DCAU score: 0.0959)\n",
      "✅ Moved: TrainArea_2122.tif (DCAU score: 0.0957)\n",
      "✅ Moved: TrainArea_1873.tif (DCAU score: 0.0953)\n",
      "✅ Moved: TrainArea_1452.tif (DCAU score: 0.0943)\n",
      "✅ Moved: TrainArea_2335.tif (DCAU score: 0.0932)\n",
      "✅ Moved: TrainArea_1164.tif (DCAU score: 0.0929)\n",
      "✅ Moved: TrainArea_2684.tif (DCAU score: 0.0927)\n",
      "✅ Moved: TrainArea_2980.tif (DCAU score: 0.0925)\n",
      "✅ Moved: TrainArea_3281.tif (DCAU score: 0.0922)\n",
      "✅ Moved: TrainArea_1827.tif (DCAU score: 0.0921)\n",
      "✅ Moved: TrainArea_2386.tif (DCAU score: 0.0920)\n",
      "✅ Moved: TrainArea_2866.tif (DCAU score: 0.0918)\n",
      "✅ Moved: TrainArea_2432.tif (DCAU score: 0.0917)\n",
      "✅ Moved: TrainArea_2434.tif (DCAU score: 0.0917)\n",
      "✅ Moved: TrainArea_2155.tif (DCAU score: 0.0917)\n",
      "✅ Moved: TrainArea_2312.tif (DCAU score: 0.0914)\n",
      "✅ Moved: TrainArea_1404.tif (DCAU score: 0.0914)\n",
      "✅ Moved: TrainArea_1052.tif (DCAU score: 0.0908)\n",
      "✅ Moved: TrainArea_1500.tif (DCAU score: 0.0907)\n",
      "✅ Moved: TrainArea_1050.tif (DCAU score: 0.0906)\n",
      "✅ Moved: TrainArea_1441.tif (DCAU score: 0.0901)\n",
      "✅ Moved: TrainArea_3234.tif (DCAU score: 0.0901)\n",
      "✅ Moved: TrainArea_3601.tif (DCAU score: 0.0900)\n",
      "✅ Moved: TrainArea_3061.tif (DCAU score: 0.0900)\n",
      "✅ Moved: TrainArea_2580.tif (DCAU score: 0.0897)\n",
      "✅ Moved: TrainArea_3414.tif (DCAU score: 0.0895)\n",
      "✅ Moved: TrainArea_1356.tif (DCAU score: 0.0894)\n",
      "✅ Moved: TrainArea_2613.tif (DCAU score: 0.0893)\n",
      "✅ Moved: TrainArea_2423.tif (DCAU score: 0.0893)\n",
      "✅ Moved: TrainArea_1523.tif (DCAU score: 0.0889)\n",
      "✅ Moved: TrainArea_2284.tif (DCAU score: 0.0886)\n",
      "✅ Moved: TrainArea_1819.tif (DCAU score: 0.0886)\n",
      "✅ Moved: TrainArea_3230.tif (DCAU score: 0.0886)\n",
      "✅ Moved: TrainArea_3412.tif (DCAU score: 0.0885)\n",
      "✅ Moved: TrainArea_3541.tif (DCAU score: 0.0883)\n",
      "✅ Moved: TrainArea_2254.tif (DCAU score: 0.0882)\n",
      "✅ Moved: TrainArea_3506.tif (DCAU score: 0.0881)\n",
      "✅ Moved: TrainArea_1099.tif (DCAU score: 0.0880)\n",
      "✅ Moved: TrainArea_3021.tif (DCAU score: 0.0880)\n",
      "✅ Moved: TrainArea_3262.tif (DCAU score: 0.0878)\n",
      "✅ Moved: TrainArea_3336.tif (DCAU score: 0.0877)\n",
      "✅ Moved: TrainArea_1043.tif (DCAU score: 0.0877)\n",
      "✅ Moved: TrainArea_2710.tif (DCAU score: 0.0876)\n",
      "✅ Moved: TrainArea_3399.tif (DCAU score: 0.0876)\n",
      "✅ Moved: TrainArea_2642.tif (DCAU score: 0.0875)\n",
      "✅ Moved: TrainArea_1865.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_2417.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_3411.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_1554.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_2353.tif (DCAU score: 0.0872)\n",
      "✅ Moved: TrainArea_2360.tif (DCAU score: 0.0871)\n",
      "✅ Moved: TrainArea_2814.tif (DCAU score: 0.0869)\n",
      "✅ Moved: TrainArea_1918.tif (DCAU score: 0.0869)\n",
      "✅ Moved: TrainArea_1106.tif (DCAU score: 0.0868)\n",
      "✅ Moved: TrainArea_2669.tif (DCAU score: 0.0867)\n",
      "✅ Moved: TrainArea_1771.tif (DCAU score: 0.0866)\n",
      "✅ Moved: TrainArea_2728.tif (DCAU score: 0.0866)\n",
      "✅ Moved: TrainArea_3202.tif (DCAU score: 0.0865)\n",
      "✅ Moved: TrainArea_3039.tif (DCAU score: 0.0865)\n",
      "✅ Moved: TrainArea_2939.tif (DCAU score: 0.0863)\n",
      "✅ Moved: TrainArea_1524.tif (DCAU score: 0.0862)\n",
      "✅ Moved: TrainArea_1734.tif (DCAU score: 0.0862)\n",
      "✅ Moved: TrainArea_1896.tif (DCAU score: 0.0861)\n",
      "✅ Moved: TrainArea_2238.tif (DCAU score: 0.0861)\n",
      "✅ Moved: TrainArea_3215.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_1028.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_1200.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_3310.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_2088.tif (DCAU score: 0.0859)\n",
      "✅ Moved: TrainArea_2664.tif (DCAU score: 0.0859)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_4\\selected_samples\\dcau_gamma_selection_log_iteration_4.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0686\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 2014\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 4 Complete ---\n",
      "Training samples: 812\n",
      "Validation Accuracy: 0.7184\n",
      "Test Accuracy: 0.7352\n",
      "Test mIoU: 0.5507\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 5/10\n",
      "============================================================\n",
      "Current training samples: 912\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.6478\n",
      "  Bareland: 0.4286\n",
      "  Rangeland: 0.0509\n",
      "  Developed Space: 0.0530\n",
      "  Road: 0.1908\n",
      "  Tree: 0.1372\n",
      "  Water: 0.1696\n",
      "  Agriculture Land: 0.1748\n",
      "  Building: 0.1473\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6333, Val Acc: 0.3977, Val mIoU: 0.2516\n",
      "Epoch 2/80 - Train Loss: 1.4747, Val Acc: 0.4033, Val mIoU: 0.2402\n",
      "Epoch 3/80 - Train Loss: 1.4120, Val Acc: 0.4466, Val mIoU: 0.3176\n",
      "Epoch 4/80 - Train Loss: 1.3345, Val Acc: 0.4664, Val mIoU: 0.3196\n",
      "Epoch 5/80 - Train Loss: 1.3035, Val Acc: 0.5192, Val mIoU: 0.3665\n",
      "Epoch 6/80 - Train Loss: 1.2731, Val Acc: 0.4999, Val mIoU: 0.3757\n",
      "Epoch 7/80 - Train Loss: 1.2470, Val Acc: 0.5009, Val mIoU: 0.3766\n",
      "Epoch 8/80 - Train Loss: 1.2170, Val Acc: 0.5114, Val mIoU: 0.3621\n",
      "Epoch 9/80 - Train Loss: 1.1998, Val Acc: 0.4938, Val mIoU: 0.3707\n",
      "Epoch 10/80 - Train Loss: 1.1873, Val Acc: 0.5861, Val mIoU: 0.4388\n",
      "Epoch 15/80 - Train Loss: 1.1265, Val Acc: 0.5566, Val mIoU: 0.3857\n",
      "Epoch 20/80 - Train Loss: 1.0119, Val Acc: 0.5653, Val mIoU: 0.4432\n",
      "Epoch 25/80 - Train Loss: 0.9732, Val Acc: 0.6104, Val mIoU: 0.4696\n",
      "Epoch 30/80 - Train Loss: 0.9060, Val Acc: 0.6393, Val mIoU: 0.4771\n",
      "Epoch 35/80 - Train Loss: 0.8149, Val Acc: 0.6585, Val mIoU: 0.5234\n",
      "Epoch 40/80 - Train Loss: 0.8117, Val Acc: 0.6276, Val mIoU: 0.4721\n",
      "Epoch 45/80 - Train Loss: 0.8018, Val Acc: 0.6581, Val mIoU: 0.5092\n",
      "Epoch 50/80 - Train Loss: 0.7216, Val Acc: 0.6629, Val mIoU: 0.5301\n",
      "Epoch 55/80 - Train Loss: 0.6649, Val Acc: 0.6697, Val mIoU: 0.5405\n",
      "Epoch 60/80 - Train Loss: 0.6356, Val Acc: 0.6644, Val mIoU: 0.5388\n",
      "Epoch 65/80 - Train Loss: 0.5956, Val Acc: 0.6887, Val mIoU: 0.5450\n",
      "Epoch 70/80 - Train Loss: 0.5292, Val Acc: 0.7036, Val mIoU: 0.5755\n",
      "Epoch 75/80 - Train Loss: 0.4985, Val Acc: 0.6863, Val mIoU: 0.5433\n",
      "Epoch 80/80 - Train Loss: 0.4911, Val Acc: 0.7157, Val mIoU: 0.5757\n",
      "Training completed after 80 epochs\n",
      "Training completed in 16495.47 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_5\\model_iteration_5.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.7287\n",
      "Test mIoU: 0.5816\n",
      "Test Loss: 0.6573\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 5 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.1668, Weight=0.0710\n",
      "  Bareland: Gap=0.7102, Weight=0.1465\n",
      "  Rangeland: Gap=0.4426, Weight=0.1156\n",
      "  Developed Space: Gap=0.5694, Weight=0.1312\n",
      "  Road: Gap=0.5329, Weight=0.1269\n",
      "  Tree: Gap=0.3194, Weight=0.0982\n",
      "  Water: Gap=0.2641, Weight=0.0893\n",
      "  Agriculture Land: Gap=0.4577, Weight=0.1176\n",
      "  Building: Gap=0.3556, Weight=0.1037\n",
      "Available pool samples: 2014\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0556\n",
      "  σ(t) = 0.0212\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0662\n",
      "  Samples passing threshold: 744/2014\n",
      "Top 5 DCAU scores: [0.10604122281074524, 0.10354124754667282, 0.10246804356575012, 0.10096576809883118, 0.0970059186220169]\n",
      "✅ Moved: TrainArea_3244.tif (DCAU score: 0.1060)\n",
      "✅ Moved: TrainArea_3657.tif (DCAU score: 0.1035)\n",
      "✅ Moved: TrainArea_1079.tif (DCAU score: 0.1025)\n",
      "✅ Moved: TrainArea_1713.tif (DCAU score: 0.1010)\n",
      "✅ Moved: TrainArea_2260.tif (DCAU score: 0.0970)\n",
      "✅ Moved: TrainArea_1265.tif (DCAU score: 0.0957)\n",
      "✅ Moved: TrainArea_1909.tif (DCAU score: 0.0950)\n",
      "✅ Moved: TrainArea_1965.tif (DCAU score: 0.0945)\n",
      "✅ Moved: TrainArea_3286.tif (DCAU score: 0.0945)\n",
      "✅ Moved: TrainArea_2361.tif (DCAU score: 0.0942)\n",
      "✅ Moved: TrainArea_2955.tif (DCAU score: 0.0934)\n",
      "✅ Moved: TrainArea_1288.tif (DCAU score: 0.0928)\n",
      "✅ Moved: TrainArea_1968.tif (DCAU score: 0.0922)\n",
      "✅ Moved: TrainArea_2177.tif (DCAU score: 0.0922)\n",
      "✅ Moved: TrainArea_1952.tif (DCAU score: 0.0922)\n",
      "✅ Moved: TrainArea_2003.tif (DCAU score: 0.0921)\n",
      "✅ Moved: TrainArea_1214.tif (DCAU score: 0.0920)\n",
      "✅ Moved: TrainArea_3643.tif (DCAU score: 0.0916)\n",
      "✅ Moved: TrainArea_3579.tif (DCAU score: 0.0914)\n",
      "✅ Moved: TrainArea_2295.tif (DCAU score: 0.0912)\n",
      "✅ Moved: TrainArea_2571.tif (DCAU score: 0.0908)\n",
      "✅ Moved: TrainArea_2469.tif (DCAU score: 0.0908)\n",
      "✅ Moved: TrainArea_2970.tif (DCAU score: 0.0907)\n",
      "✅ Moved: TrainArea_2952.tif (DCAU score: 0.0903)\n",
      "✅ Moved: TrainArea_3116.tif (DCAU score: 0.0901)\n",
      "✅ Moved: TrainArea_3122.tif (DCAU score: 0.0900)\n",
      "✅ Moved: TrainArea_2452.tif (DCAU score: 0.0899)\n",
      "✅ Moved: TrainArea_3391.tif (DCAU score: 0.0896)\n",
      "✅ Moved: TrainArea_1951.tif (DCAU score: 0.0893)\n",
      "✅ Moved: TrainArea_1985.tif (DCAU score: 0.0890)\n",
      "✅ Moved: TrainArea_2658.tif (DCAU score: 0.0890)\n",
      "✅ Moved: TrainArea_1755.tif (DCAU score: 0.0887)\n",
      "✅ Moved: TrainArea_1074.tif (DCAU score: 0.0886)\n",
      "✅ Moved: TrainArea_2575.tif (DCAU score: 0.0883)\n",
      "✅ Moved: TrainArea_3035.tif (DCAU score: 0.0881)\n",
      "✅ Moved: TrainArea_2389.tif (DCAU score: 0.0880)\n",
      "✅ Moved: TrainArea_2614.tif (DCAU score: 0.0878)\n",
      "✅ Moved: TrainArea_2143.tif (DCAU score: 0.0877)\n",
      "✅ Moved: TrainArea_1888.tif (DCAU score: 0.0876)\n",
      "✅ Moved: TrainArea_2485.tif (DCAU score: 0.0876)\n",
      "✅ Moved: TrainArea_1208.tif (DCAU score: 0.0875)\n",
      "✅ Moved: TrainArea_2082.tif (DCAU score: 0.0875)\n",
      "✅ Moved: TrainArea_1525.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_2131.tif (DCAU score: 0.0874)\n",
      "✅ Moved: TrainArea_3339.tif (DCAU score: 0.0871)\n",
      "✅ Moved: TrainArea_2030.tif (DCAU score: 0.0870)\n",
      "✅ Moved: TrainArea_3241.tif (DCAU score: 0.0869)\n",
      "✅ Moved: TrainArea_3136.tif (DCAU score: 0.0867)\n",
      "✅ Moved: TrainArea_1559.tif (DCAU score: 0.0867)\n",
      "✅ Moved: TrainArea_1371.tif (DCAU score: 0.0866)\n",
      "✅ Moved: TrainArea_1581.tif (DCAU score: 0.0864)\n",
      "✅ Moved: TrainArea_3694.tif (DCAU score: 0.0864)\n",
      "✅ Moved: TrainArea_3072.tif (DCAU score: 0.0864)\n",
      "✅ Moved: TrainArea_3389.tif (DCAU score: 0.0863)\n",
      "✅ Moved: TrainArea_3140.tif (DCAU score: 0.0862)\n",
      "✅ Moved: TrainArea_1616.tif (DCAU score: 0.0862)\n",
      "✅ Moved: TrainArea_1020.tif (DCAU score: 0.0861)\n",
      "✅ Moved: TrainArea_1184.tif (DCAU score: 0.0861)\n",
      "✅ Moved: TrainArea_3510.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_2292.tif (DCAU score: 0.0858)\n",
      "✅ Moved: TrainArea_1398.tif (DCAU score: 0.0857)\n",
      "✅ Moved: TrainArea_1228.tif (DCAU score: 0.0857)\n",
      "✅ Moved: TrainArea_2731.tif (DCAU score: 0.0855)\n",
      "✅ Moved: TrainArea_2889.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_2007.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_3029.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_1832.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_2120.tif (DCAU score: 0.0853)\n",
      "✅ Moved: TrainArea_2729.tif (DCAU score: 0.0852)\n",
      "✅ Moved: TrainArea_1447.tif (DCAU score: 0.0851)\n",
      "✅ Moved: TrainArea_2719.tif (DCAU score: 0.0851)\n",
      "✅ Moved: TrainArea_1170.tif (DCAU score: 0.0849)\n",
      "✅ Moved: TrainArea_1363.tif (DCAU score: 0.0849)\n",
      "✅ Moved: TrainArea_2682.tif (DCAU score: 0.0849)\n",
      "✅ Moved: TrainArea_3640.tif (DCAU score: 0.0846)\n",
      "✅ Moved: TrainArea_2243.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_2474.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_2095.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_1521.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_3425.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_2379.tif (DCAU score: 0.0845)\n",
      "✅ Moved: TrainArea_1522.tif (DCAU score: 0.0844)\n",
      "✅ Moved: TrainArea_1607.tif (DCAU score: 0.0844)\n",
      "✅ Moved: TrainArea_1453.tif (DCAU score: 0.0844)\n",
      "✅ Moved: TrainArea_3675.tif (DCAU score: 0.0844)\n",
      "✅ Moved: TrainArea_2444.tif (DCAU score: 0.0842)\n",
      "✅ Moved: TrainArea_2808.tif (DCAU score: 0.0841)\n",
      "✅ Moved: TrainArea_1830.tif (DCAU score: 0.0841)\n",
      "✅ Moved: TrainArea_2584.tif (DCAU score: 0.0841)\n",
      "✅ Moved: TrainArea_3646.tif (DCAU score: 0.0840)\n",
      "✅ Moved: TrainArea_2037.tif (DCAU score: 0.0840)\n",
      "✅ Moved: TrainArea_1259.tif (DCAU score: 0.0839)\n",
      "✅ Moved: TrainArea_1103.tif (DCAU score: 0.0838)\n",
      "✅ Moved: TrainArea_2199.tif (DCAU score: 0.0837)\n",
      "✅ Moved: TrainArea_2051.tif (DCAU score: 0.0835)\n",
      "✅ Moved: TrainArea_1931.tif (DCAU score: 0.0835)\n",
      "✅ Moved: TrainArea_2097.tif (DCAU score: 0.0834)\n",
      "✅ Moved: TrainArea_1938.tif (DCAU score: 0.0833)\n",
      "✅ Moved: TrainArea_1315.tif (DCAU score: 0.0831)\n",
      "✅ Moved: TrainArea_2296.tif (DCAU score: 0.0831)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_5\\selected_samples\\dcau_gamma_selection_log_iteration_5.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0662\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 1914\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 5 Complete ---\n",
      "Training samples: 912\n",
      "Validation Accuracy: 0.7157\n",
      "Test Accuracy: 0.7287\n",
      "Test mIoU: 0.5816\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 6/10\n",
      "============================================================\n",
      "Current training samples: 1012\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.7259\n",
      "  Bareland: 0.4201\n",
      "  Rangeland: 0.0487\n",
      "  Developed Space: 0.0443\n",
      "  Road: 0.1673\n",
      "  Tree: 0.1339\n",
      "  Water: 0.1528\n",
      "  Agriculture Land: 0.1745\n",
      "  Building: 0.1325\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6356, Val Acc: 0.4112, Val mIoU: 0.2446\n",
      "Epoch 2/80 - Train Loss: 1.4490, Val Acc: 0.4605, Val mIoU: 0.2820\n",
      "Epoch 3/80 - Train Loss: 1.4073, Val Acc: 0.4713, Val mIoU: 0.3261\n",
      "Epoch 4/80 - Train Loss: 1.3448, Val Acc: 0.4329, Val mIoU: 0.2855\n",
      "Epoch 5/80 - Train Loss: 1.3461, Val Acc: 0.4980, Val mIoU: 0.3646\n",
      "Epoch 6/80 - Train Loss: 1.2809, Val Acc: 0.5470, Val mIoU: 0.3898\n",
      "Epoch 7/80 - Train Loss: 1.2653, Val Acc: 0.5046, Val mIoU: 0.3805\n",
      "Epoch 8/80 - Train Loss: 1.2388, Val Acc: 0.5126, Val mIoU: 0.3875\n",
      "Epoch 9/80 - Train Loss: 1.2035, Val Acc: 0.5244, Val mIoU: 0.3971\n",
      "Epoch 10/80 - Train Loss: 1.2130, Val Acc: 0.5162, Val mIoU: 0.3891\n",
      "Epoch 15/80 - Train Loss: 1.1226, Val Acc: 0.5454, Val mIoU: 0.3834\n",
      "Epoch 20/80 - Train Loss: 1.0256, Val Acc: 0.5910, Val mIoU: 0.4580\n",
      "Epoch 25/80 - Train Loss: 0.9444, Val Acc: 0.6303, Val mIoU: 0.4945\n",
      "Epoch 30/80 - Train Loss: 0.8813, Val Acc: 0.6391, Val mIoU: 0.4808\n",
      "Epoch 35/80 - Train Loss: 0.8144, Val Acc: 0.6408, Val mIoU: 0.5113\n",
      "Epoch 40/80 - Train Loss: 0.7759, Val Acc: 0.6639, Val mIoU: 0.5273\n",
      "Epoch 45/80 - Train Loss: 0.7437, Val Acc: 0.6688, Val mIoU: 0.5266\n",
      "Epoch 50/80 - Train Loss: 0.6718, Val Acc: 0.6873, Val mIoU: 0.5401\n",
      "Epoch 55/80 - Train Loss: 0.6550, Val Acc: 0.6588, Val mIoU: 0.5353\n",
      "Epoch 60/80 - Train Loss: 0.5903, Val Acc: 0.6892, Val mIoU: 0.5654\n",
      "Epoch 65/80 - Train Loss: 0.5709, Val Acc: 0.6842, Val mIoU: 0.5445\n",
      "Epoch 70/80 - Train Loss: 0.4962, Val Acc: 0.7245, Val mIoU: 0.5870\n",
      "Epoch 75/80 - Train Loss: 0.4459, Val Acc: 0.6459, Val mIoU: 0.4970\n",
      "Epoch 80/80 - Train Loss: 0.3999, Val Acc: 0.7309, Val mIoU: 0.5917\n",
      "Training completed after 80 epochs\n",
      "Training completed in 17321.24 seconds\n",
      "✓ Model saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_6\\model_iteration_6.pth\n",
      "\n",
      "--- Test Evaluation ---\n",
      "Test Accuracy: 0.7396\n",
      "Test mIoU: 0.5898\n",
      "Test Loss: 0.7605\n",
      "\n",
      "--- Sample Selection ---\n",
      "\n",
      "--- DCAU Sample Selection (γ=0.5, α=0.5) for Iteration 6 ---\n",
      "Computing class performance gaps...\n",
      "Class Performance Analysis:\n",
      "  Background: Gap=0.1486, Weight=0.0684\n",
      "  Bareland: Gap=0.6859, Weight=0.1469\n",
      "  Rangeland: Gap=0.4254, Weight=0.1157\n",
      "  Developed Space: Gap=0.5284, Weight=0.1289\n",
      "  Road: Gap=0.5203, Weight=0.1279\n",
      "  Tree: Gap=0.3053, Weight=0.0980\n",
      "  Water: Gap=0.2533, Weight=0.0892\n",
      "  Agriculture Land: Gap=0.4455, Weight=0.1184\n",
      "  Building: Gap=0.3618, Weight=0.1067\n",
      "Available pool samples: 1914\n",
      "Computing DCAU scores...\n",
      "Adaptive Thresholding Results:\n",
      "  μ(t) = 0.0502\n",
      "  σ(t) = 0.0220\n",
      "  γ = 0.5\n",
      "  Threshold θ(t) = 0.0612\n",
      "  Samples passing threshold: 779/1914\n",
      "Top 5 DCAU scores: [0.0951843112707138, 0.0902416855096817, 0.08808602392673492, 0.08672380447387695, 0.08639289438724518]\n",
      "✅ Moved: TrainArea_1361.tif (DCAU score: 0.0952)\n",
      "✅ Moved: TrainArea_2180.tif (DCAU score: 0.0902)\n",
      "✅ Moved: TrainArea_2310.tif (DCAU score: 0.0881)\n",
      "✅ Moved: TrainArea_3429.tif (DCAU score: 0.0867)\n",
      "✅ Moved: TrainArea_2600.tif (DCAU score: 0.0864)\n",
      "✅ Moved: TrainArea_1961.tif (DCAU score: 0.0860)\n",
      "✅ Moved: TrainArea_3036.tif (DCAU score: 0.0858)\n",
      "✅ Moved: TrainArea_2595.tif (DCAU score: 0.0856)\n",
      "✅ Moved: TrainArea_1172.tif (DCAU score: 0.0855)\n",
      "✅ Moved: TrainArea_1498.tif (DCAU score: 0.0855)\n",
      "✅ Moved: TrainArea_1989.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_2945.tif (DCAU score: 0.0854)\n",
      "✅ Moved: TrainArea_1599.tif (DCAU score: 0.0850)\n",
      "✅ Moved: TrainArea_3350.tif (DCAU score: 0.0841)\n",
      "✅ Moved: TrainArea_3200.tif (DCAU score: 0.0840)\n",
      "✅ Moved: TrainArea_2050.tif (DCAU score: 0.0836)\n",
      "✅ Moved: TrainArea_3056.tif (DCAU score: 0.0836)\n",
      "✅ Moved: TrainArea_3435.tif (DCAU score: 0.0833)\n",
      "✅ Moved: TrainArea_3437.tif (DCAU score: 0.0829)\n",
      "✅ Moved: TrainArea_3688.tif (DCAU score: 0.0825)\n",
      "✅ Moved: TrainArea_3065.tif (DCAU score: 0.0821)\n",
      "✅ Moved: TrainArea_2860.tif (DCAU score: 0.0817)\n",
      "✅ Moved: TrainArea_2121.tif (DCAU score: 0.0816)\n",
      "✅ Moved: TrainArea_2024.tif (DCAU score: 0.0816)\n",
      "✅ Moved: TrainArea_2136.tif (DCAU score: 0.0816)\n",
      "✅ Moved: TrainArea_3667.tif (DCAU score: 0.0815)\n",
      "✅ Moved: TrainArea_3104.tif (DCAU score: 0.0813)\n",
      "✅ Moved: TrainArea_1782.tif (DCAU score: 0.0811)\n",
      "✅ Moved: TrainArea_1672.tif (DCAU score: 0.0810)\n",
      "✅ Moved: TrainArea_2640.tif (DCAU score: 0.0809)\n",
      "✅ Moved: TrainArea_1193.tif (DCAU score: 0.0808)\n",
      "✅ Moved: TrainArea_3301.tif (DCAU score: 0.0806)\n",
      "✅ Moved: TrainArea_1430.tif (DCAU score: 0.0805)\n",
      "✅ Moved: TrainArea_2501.tif (DCAU score: 0.0804)\n",
      "✅ Moved: TrainArea_2275.tif (DCAU score: 0.0803)\n",
      "✅ Moved: TrainArea_1643.tif (DCAU score: 0.0803)\n",
      "✅ Moved: TrainArea_2625.tif (DCAU score: 0.0802)\n",
      "✅ Moved: TrainArea_3189.tif (DCAU score: 0.0802)\n",
      "✅ Moved: TrainArea_1083.tif (DCAU score: 0.0801)\n",
      "✅ Moved: TrainArea_3304.tif (DCAU score: 0.0801)\n",
      "✅ Moved: TrainArea_3248.tif (DCAU score: 0.0800)\n",
      "✅ Moved: TrainArea_2011.tif (DCAU score: 0.0800)\n",
      "✅ Moved: TrainArea_2273.tif (DCAU score: 0.0799)\n",
      "✅ Moved: TrainArea_1424.tif (DCAU score: 0.0799)\n",
      "✅ Moved: TrainArea_2244.tif (DCAU score: 0.0798)\n",
      "✅ Moved: TrainArea_3472.tif (DCAU score: 0.0796)\n",
      "✅ Moved: TrainArea_1346.tif (DCAU score: 0.0794)\n",
      "✅ Moved: TrainArea_1394.tif (DCAU score: 0.0793)\n",
      "✅ Moved: TrainArea_2210.tif (DCAU score: 0.0793)\n",
      "✅ Moved: TrainArea_1490.tif (DCAU score: 0.0793)\n",
      "✅ Moved: TrainArea_1728.tif (DCAU score: 0.0792)\n",
      "✅ Moved: TrainArea_2663.tif (DCAU score: 0.0792)\n",
      "✅ Moved: TrainArea_2368.tif (DCAU score: 0.0792)\n",
      "✅ Moved: TrainArea_1188.tif (DCAU score: 0.0791)\n",
      "✅ Moved: TrainArea_1695.tif (DCAU score: 0.0790)\n",
      "✅ Moved: TrainArea_3564.tif (DCAU score: 0.0790)\n",
      "✅ Moved: TrainArea_2314.tif (DCAU score: 0.0790)\n",
      "✅ Moved: TrainArea_3505.tif (DCAU score: 0.0789)\n",
      "✅ Moved: TrainArea_2067.tif (DCAU score: 0.0789)\n",
      "✅ Moved: TrainArea_1497.tif (DCAU score: 0.0789)\n",
      "✅ Moved: TrainArea_2489.tif (DCAU score: 0.0788)\n",
      "✅ Moved: TrainArea_3002.tif (DCAU score: 0.0788)\n",
      "✅ Moved: TrainArea_3168.tif (DCAU score: 0.0787)\n",
      "✅ Moved: TrainArea_3179.tif (DCAU score: 0.0787)\n",
      "✅ Moved: TrainArea_1744.tif (DCAU score: 0.0785)\n",
      "✅ Moved: TrainArea_2400.tif (DCAU score: 0.0785)\n",
      "✅ Moved: TrainArea_3582.tif (DCAU score: 0.0784)\n",
      "✅ Moved: TrainArea_1767.tif (DCAU score: 0.0783)\n",
      "✅ Moved: TrainArea_3129.tif (DCAU score: 0.0783)\n",
      "✅ Moved: TrainArea_3023.tif (DCAU score: 0.0782)\n",
      "✅ Moved: TrainArea_3542.tif (DCAU score: 0.0782)\n",
      "✅ Moved: TrainArea_1247.tif (DCAU score: 0.0782)\n",
      "✅ Moved: TrainArea_1458.tif (DCAU score: 0.0781)\n",
      "✅ Moved: TrainArea_2252.tif (DCAU score: 0.0781)\n",
      "✅ Moved: TrainArea_2495.tif (DCAU score: 0.0780)\n",
      "✅ Moved: TrainArea_2752.tif (DCAU score: 0.0780)\n",
      "✅ Moved: TrainArea_3185.tif (DCAU score: 0.0780)\n",
      "✅ Moved: TrainArea_1236.tif (DCAU score: 0.0779)\n",
      "✅ Moved: TrainArea_2026.tif (DCAU score: 0.0779)\n",
      "✅ Moved: TrainArea_2686.tif (DCAU score: 0.0779)\n",
      "✅ Moved: TrainArea_2165.tif (DCAU score: 0.0779)\n",
      "✅ Moved: TrainArea_2028.tif (DCAU score: 0.0778)\n",
      "✅ Moved: TrainArea_1336.tif (DCAU score: 0.0778)\n",
      "✅ Moved: TrainArea_2228.tif (DCAU score: 0.0778)\n",
      "✅ Moved: TrainArea_2032.tif (DCAU score: 0.0777)\n",
      "✅ Moved: TrainArea_1928.tif (DCAU score: 0.0777)\n",
      "✅ Moved: TrainArea_2248.tif (DCAU score: 0.0777)\n",
      "✅ Moved: TrainArea_2982.tif (DCAU score: 0.0777)\n",
      "✅ Moved: TrainArea_1347.tif (DCAU score: 0.0776)\n",
      "✅ Moved: TrainArea_2678.tif (DCAU score: 0.0776)\n",
      "✅ Moved: TrainArea_1503.tif (DCAU score: 0.0776)\n",
      "✅ Moved: TrainArea_2920.tif (DCAU score: 0.0776)\n",
      "✅ Moved: TrainArea_1953.tif (DCAU score: 0.0774)\n",
      "✅ Moved: TrainArea_1675.tif (DCAU score: 0.0773)\n",
      "✅ Moved: TrainArea_2042.tif (DCAU score: 0.0772)\n",
      "✅ Moved: TrainArea_1577.tif (DCAU score: 0.0772)\n",
      "✅ Moved: TrainArea_3096.tif (DCAU score: 0.0772)\n",
      "✅ Moved: TrainArea_2301.tif (DCAU score: 0.0771)\n",
      "✅ Moved: TrainArea_1966.tif (DCAU score: 0.0771)\n",
      "✅ Moved: TrainArea_1699.tif (DCAU score: 0.0770)\n",
      "✅ DCAU-Gamma selection log saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\iteration_6\\selected_samples\\dcau_gamma_selection_log_iteration_6.csv\n",
      "\n",
      "--- DCAU-Gamma Selection Summary ---\n",
      "Gamma (γ): 0.5\n",
      "Alpha (α): 0.5\n",
      "Adaptive threshold: 0.0612\n",
      "Successfully moved: 100\n",
      "Remaining in pool: 1814\n",
      "✓ Detailed results saved: E:\\hemanth\\data\\data\\results_dcau_gamma_0.5_\\results\n",
      "\n",
      "--- Iteration 6 Complete ---\n",
      "Training samples: 1012\n",
      "Validation Accuracy: 0.7309\n",
      "Test Accuracy: 0.7396\n",
      "Test mIoU: 0.5898\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 7/10\n",
      "============================================================\n",
      "Current training samples: 1112\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.6739\n",
      "  Bareland: 0.4636\n",
      "  Rangeland: 0.0513\n",
      "  Developed Space: 0.0440\n",
      "  Road: 0.1593\n",
      "  Tree: 0.1404\n",
      "  Water: 0.1660\n",
      "  Agriculture Land: 0.1867\n",
      "  Building: 0.1147\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 80 epochs...\n",
      "Epoch 1/80 - Train Loss: 1.6486, Val Acc: 0.4362, Val mIoU: 0.2427\n",
      "Epoch 2/80 - Train Loss: 1.4390, Val Acc: 0.4712, Val mIoU: 0.3212\n",
      "Epoch 3/80 - Train Loss: 1.3786, Val Acc: 0.4580, Val mIoU: 0.3153\n",
      "Epoch 4/80 - Train Loss: 1.3226, Val Acc: 0.4798, Val mIoU: 0.3674\n",
      "Epoch 5/80 - Train Loss: 1.3018, Val Acc: 0.4917, Val mIoU: 0.3188\n",
      "Epoch 6/80 - Train Loss: 1.2634, Val Acc: 0.4808, Val mIoU: 0.3717\n",
      "Epoch 7/80 - Train Loss: 1.2486, Val Acc: 0.4933, Val mIoU: 0.3836\n",
      "Epoch 8/80 - Train Loss: 1.1984, Val Acc: 0.5419, Val mIoU: 0.4109\n",
      "Epoch 9/80 - Train Loss: 1.1977, Val Acc: 0.5224, Val mIoU: 0.3916\n",
      "Epoch 10/80 - Train Loss: 1.1830, Val Acc: 0.5489, Val mIoU: 0.4232\n",
      "Epoch 15/80 - Train Loss: 1.0489, Val Acc: 0.5871, Val mIoU: 0.4613\n",
      "Epoch 20/80 - Train Loss: 0.9727, Val Acc: 0.6038, Val mIoU: 0.4684\n",
      "Epoch 25/80 - Train Loss: 0.9137, Val Acc: 0.6072, Val mIoU: 0.4775\n"
     ]
    }
   ],
   "source": [
    "#### DCAU updated  gamma\n",
    "\n",
    "#\n",
    "\n",
    "# Fixed Active Learning Pipeline with Proper Sample Selection and Model Saving\n",
    "# Addresses sample selection issues and ensures proper model persistence\n",
    "# Added epoch tracking functionality\n",
    "\n",
    "### DCAU\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import platform\n",
    "import sys\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_system_capabilities():\n",
    "    \"\"\"Check system capabilities to determine optimal num_workers\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SYSTEM CAPABILITY CHECK\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    logical_cores = psutil.cpu_count(logical=True)\n",
    "    physical_cores = psutil.cpu_count(logical=False)\n",
    "\n",
    "    print(f\"Operating System: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Physical cores: {physical_cores}\")\n",
    "    print(f\"Logical cores: {logical_cores}\")\n",
    "\n",
    "    memory = psutil.virtual_memory()\n",
    "    total_memory_gb = memory.total / (1024**3)\n",
    "    print(f\"Total RAM: {total_memory_gb:.2f} GB\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"CUDA available: Yes, {gpu_count} GPU(s)\")\n",
    "    else:\n",
    "        print(\"CUDA available: No\")\n",
    "\n",
    "    # Conservative approach for Windows\n",
    "    recommended_workers = 0 if platform.system() == \"Windows\" else min(2, physical_cores)\n",
    "    print(f\"Recommended num_workers: {recommended_workers}\")\n",
    "\n",
    "    return recommended_workers\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Class Names\n",
    "class_names = [\n",
    "    \"Background\", \"Bareland\", \"Rangeland\", \"Developed Space\", \"Road\",\n",
    "    \"Tree\", \"Water\", \"Agriculture Land\", \"Building\"\n",
    "]\n",
    "num_classes = len(class_names)\n",
    "COLOR_MAP = {\n",
    "    0: (0, 0, 0),        # Background - Black\n",
    "    1: (128, 0, 0),      # Bareland - Maroon\n",
    "    2: (0, 255, 36),     # Rangeland - Green\n",
    "    3: (148, 148, 148),  # Developed Space - Gray\n",
    "    4: (255, 255, 255),  # Road - White\n",
    "    5: (34, 97, 38),     # Tree - Dark Green\n",
    "    6: (0, 69, 255),     # Water - Blue\n",
    "    7: (75, 181, 73),    # Agriculture Land - Light Green\n",
    "    8: (222, 31, 7)      # Building - Red\n",
    "}\n",
    "# UNet Model Definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(3, 64)\n",
    "        self.contracting_12 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_21 = self.conv_block(64, 128)\n",
    "        self.contracting_22 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_31 = self.conv_block(128, 256)\n",
    "        self.contracting_32 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_41 = self.conv_block(256, 512)\n",
    "        self.contracting_42 = nn.MaxPool2d(2, 2)\n",
    "        self.middle = self.conv_block(512, 1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(1024, 512, 3, 2, 1, 1)\n",
    "        self.expansive_12 = self.conv_block(1024, 512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(512, 256, 3, 2, 1, 1)\n",
    "        self.expansive_22 = self.conv_block(512, 256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "        self.expansive_32 = self.conv_block(256, 128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n",
    "        self.expansive_42 = self.conv_block(128, 64)\n",
    "        self.output = nn.Conv2d(64, num_classes, 3, 1, 1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.contracting_11(x)\n",
    "        p1 = self.contracting_12(c1)\n",
    "        c2 = self.contracting_21(p1)\n",
    "        p2 = self.contracting_22(c2)\n",
    "        c3 = self.contracting_31(p2)\n",
    "        p3 = self.contracting_32(c3)\n",
    "        c4 = self.contracting_41(p3)\n",
    "        p4 = self.contracting_42(c4)\n",
    "        middle = self.middle(p4)\n",
    "        u1 = self.expansive_11(middle)\n",
    "        u1 = self.expansive_12(torch.cat((u1, c4), dim=1))\n",
    "        u2 = self.expansive_21(u1)\n",
    "        u2 = self.expansive_22(torch.cat((u2, c3), dim=1))\n",
    "        u3 = self.expansive_31(u2)\n",
    "        u3 = self.expansive_32(torch.cat((u3, c2), dim=1))\n",
    "        u4 = self.expansive_41(u3)\n",
    "        u4 = self.expansive_42(torch.cat((u4, c1), dim=1))\n",
    "        output = self.output(u4)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        # Load image (RGB)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "        # Load mask as GRAYSCALE (single channel)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Failed to load mask: {mask_path}\")\n",
    "\n",
    "        # Resize\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Convert image to tensor [C, H, W] and normalize\n",
    "        image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Convert mask to tensor [H, W] - NO channel dimension for segmentation masks\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        mask = torch.clamp(mask, 0, 8)  # Ensure valid class indices\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.has_labels = label_dir is not None\n",
    "\n",
    "        if self.has_labels:\n",
    "            self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        else:\n",
    "            self.label_files = [None] * len(self.image_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        image_tensor = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        if self.has_labels and self.label_files[idx]:\n",
    "            label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "            if os.path.exists(label_path):\n",
    "                # Load label as GRAYSCALE\n",
    "                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if label is not None:\n",
    "                    label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "                    label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "                    label_tensor = torch.clamp(label_tensor, 0, 8)\n",
    "                else:\n",
    "                    label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "            else:\n",
    "                label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "        else:\n",
    "            label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "\n",
    "        return image_tensor, label_tensor, self.image_files[idx]\n",
    "\n",
    "def apply_color_map(mask, color_map):\n",
    "    \"\"\"Apply color map to segmentation mask\"\"\"\n",
    "    h, w = mask.shape\n",
    "    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in color_map.items():\n",
    "        colored_mask[mask == class_id] = color\n",
    "\n",
    "    return colored_mask\n",
    "\n",
    "def create_safe_dataloader(dataset, batch_size, shuffle=False, num_workers=None):\n",
    "    \"\"\"Create a DataLoader with safe num_workers handling\"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = OPTIMAL_WORKERS\n",
    "\n",
    "    if platform.system() == \"Windows\":\n",
    "        num_workers = 0\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available() and num_workers == 0\n",
    "    )\n",
    "\n",
    "def compute_miou(preds, targets, num_classes=9):\n",
    "    \"\"\"Compute mean IoU and class-wise IoU\"\"\"\n",
    "    iou_per_class = np.zeros(num_classes)\n",
    "    preds = preds.flatten()\n",
    "    targets = targets.flatten()\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if (targets == cls).sum() == 0:\n",
    "            iou_per_class[cls] = np.nan\n",
    "            continue\n",
    "        iou_per_class[cls] = jaccard_score(targets == cls, preds == cls, zero_division=0)\n",
    "\n",
    "    return np.nanmean(iou_per_class), iou_per_class\n",
    "\n",
    "\n",
    "def compute_class_performance_gaps(model, val_loader, device, num_classes=9):\n",
    "    \"\"\"Compute IoU-based performance gaps for each class with moderated weighting\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Calculate class-wise IoU and performance gaps\n",
    "    class_gaps = np.zeros(num_classes)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if (all_targets == cls).sum() == 0:\n",
    "            class_gaps[cls] = 0.1  # Minimum gap for classes without samples\n",
    "            continue\n",
    "\n",
    "        # Calculate IoU for this class\n",
    "        tp = np.sum((all_preds == cls) & (all_targets == cls))\n",
    "        fp = np.sum((all_preds == cls) & (all_targets != cls))\n",
    "        fn = np.sum((all_preds != cls) & (all_targets == cls))\n",
    "\n",
    "        if tp + fp + fn == 0:\n",
    "            iou = 1.0  # Perfect if no predictions or targets\n",
    "        else:\n",
    "            iou = tp / (tp + fp + fn)\n",
    "\n",
    "        # **CHANGE 1: Moderate the Weighting - Floor the gap**\n",
    "        class_gaps[cls] = max(0.1, 1.0 - iou)  # Floor the gap to prevent zero weights\n",
    "\n",
    "    return class_gaps\n",
    "\n",
    "\n",
    "def compute_dynamic_weights(class_gaps, alpha=1.0, use_softer_weighting=True, regularize=True):\n",
    "    \"\"\"Compute dynamic weights based on performance gaps with improvements\"\"\"\n",
    "\n",
    "    if use_softer_weighting:\n",
    "        # **CHANGE 2: Use softer weighting - less aggressive**\n",
    "        weighted_gaps = np.sqrt(class_gaps)  # Less aggressive than power\n",
    "    else:\n",
    "        # Apply exponential weighting (original approach)\n",
    "        weighted_gaps = np.power(class_gaps, alpha)\n",
    "\n",
    "    # Normalize to create probability distribution\n",
    "    total_weighted = np.sum(weighted_gaps)\n",
    "    if total_weighted == 0:\n",
    "        # If all gaps are zero, use uniform weighting\n",
    "        weights = np.ones(len(class_gaps)) / len(class_gaps)\n",
    "    else:\n",
    "        weights = weighted_gaps / total_weighted\n",
    "\n",
    "    if regularize:\n",
    "        # **CHANGE 4: Regularized Class Weights - Prevent extreme weighting**\n",
    "        weights = np.clip(weights, a_min=0.1/len(class_gaps), a_max=2.0/len(class_gaps))\n",
    "        # Renormalize after clipping\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def compute_dcau_score(prob_map, dynamic_weights):\n",
    "    \"\"\"\n",
    "    Compute DCAU score as per paper equation (5) and (6)\n",
    "    \n",
    "    Args:\n",
    "        prob_map: [C, H, W] probability map for each class\n",
    "        dynamic_weights: [C] weights for each class based on performance gaps\n",
    "    \n",
    "    Returns:\n",
    "        dcau_score: scalar uncertainty score for the image\n",
    "    \"\"\"\n",
    "    # Ensure weights are on the same device as prob_map\n",
    "    if torch.is_tensor(dynamic_weights):\n",
    "        weights = dynamic_weights.to(prob_map.device)\n",
    "    else:\n",
    "        weights = torch.tensor(dynamic_weights, dtype=prob_map.dtype, device=prob_map.device)\n",
    "    \n",
    "    # Compute pixel-level entropy H(p_i) - Equation (4)\n",
    "    entropy_map = -torch.sum(prob_map * torch.log(prob_map + 1e-10), dim=0)  # [H, W]\n",
    "    \n",
    "    # Apply dynamic weights to compute H_dyn(p_i) - Equation (5)\n",
    "    N_pixels = prob_map.size(1) * prob_map.size(2)  # H * W\n",
    "    dynamic_entropy = torch.zeros_like(entropy_map)\n",
    "    \n",
    "    for k in range(prob_map.size(0)):  # For each class\n",
    "        # Apply equation (5): sum over k of (p_i,k * w_k(t) * H(p_i))\n",
    "        dynamic_entropy += prob_map[k] * weights[k] * entropy_map\n",
    "    \n",
    "    # Compute image-level DCAU score - Equation (6)\n",
    "    dcau_score = torch.mean(dynamic_entropy)\n",
    "    \n",
    "    return dcau_score\n",
    "    \n",
    "def apply_adaptive_thresholding(uncertainties, gamma=0.5):\n",
    "    \"\"\"\n",
    "    Apply adaptive thresholding as per paper equation (7)\n",
    "    \n",
    "    Args:\n",
    "        uncertainties: list of uncertainty scores\n",
    "        gamma: scaling parameter (default 0.5 as in paper)\n",
    "    \n",
    "    Returns:\n",
    "        filtered_indices: indices of samples that pass the threshold\n",
    "        threshold: computed threshold value\n",
    "    \"\"\"\n",
    "    # Convert to tensor if needed\n",
    "    if not torch.is_tensor(uncertainties[0]):\n",
    "        uncertainty_tensor = torch.tensor([u.item() if torch.is_tensor(u) else u for u in uncertainties])\n",
    "    else:\n",
    "        uncertainty_tensor = torch.stack(uncertainties)\n",
    "    \n",
    "    # Calculate μ(t) and σ(t) - Equation (7)\n",
    "    mu_t = torch.mean(uncertainty_tensor)\n",
    "    sigma_t = torch.std(uncertainty_tensor)\n",
    "    \n",
    "    # Calculate adaptive threshold θ(t) = μ(t) + γ · σ(t)\n",
    "    threshold = mu_t + gamma * sigma_t\n",
    "    \n",
    "    # Find indices where DCAU(x) ≥ θ(t)\n",
    "    filtered_indices = torch.where(uncertainty_tensor >= threshold)[0].tolist()\n",
    "    \n",
    "    print(f\"Adaptive Thresholding Results:\")\n",
    "    print(f\"  μ(t) = {mu_t:.4f}\")\n",
    "    print(f\"  σ(t) = {sigma_t:.4f}\")\n",
    "    print(f\"  γ = {gamma}\")\n",
    "    print(f\"  Threshold θ(t) = {threshold:.4f}\")\n",
    "    print(f\"  Samples passing threshold: {len(filtered_indices)}/{len(uncertainties)}\")\n",
    "    \n",
    "    return filtered_indices, threshold.item()\n",
    "# \n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model and return comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels = 0\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_pixels += targets.numel()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "    accuracy = total_correct / total_pixels if total_pixels > 0 else 0.0\n",
    "    avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else float('inf')\n",
    "\n",
    "    # Compute mIoU\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    miou, class_ious = compute_miou(all_preds, all_targets)\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_accuracies = []\n",
    "    for cls in range(num_classes):\n",
    "        mask = (all_targets == cls)\n",
    "        if mask.sum() > 0:\n",
    "            class_acc = np.mean(all_preds[mask] == all_targets[mask])\n",
    "            class_accuracies.append(class_acc)\n",
    "        else:\n",
    "            class_accuracies.append(0.0)\n",
    "\n",
    "    return accuracy, avg_loss, miou, class_ious, class_accuracies\n",
    "\n",
    "def save_model(model, iteration_dir, iteration):\n",
    "    \"\"\"Save model with proper handling of DataParallel\"\"\"\n",
    "    model_path = os.path.join(iteration_dir, f'model_iteration_{iteration}.pth')\n",
    "\n",
    "    # Handle DataParallel model\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model_state = model.module.state_dict()\n",
    "    else:\n",
    "        model_state = model.state_dict()\n",
    "\n",
    "    # Save model state\n",
    "    torch.save({\n",
    "        'model_state_dict': model_state,\n",
    "        'iteration': iteration,\n",
    "        'num_classes': num_classes,\n",
    "        'model_type': 'UNet'\n",
    "    }, model_path)\n",
    "\n",
    "    print(f\"✓ Model saved: {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "def train_model_with_validation(train_loader, val_loader, model, criterion, optimizer,\n",
    "                               num_epochs, device):\n",
    "    \"\"\"Train model with validation and early stopping - returns epochs trained\"\"\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "   # early_stopping = EarlyStopping(patience=patience, min_delta=min_delta, restore_best_weights=True)\n",
    "\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "    val_mious = []\n",
    "\n",
    "  #  print(f\"Starting training with early stopping (patience={patience}, min_delta={min_delta})...\")\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "\n",
    "    epochs_trained = 0  # Track actual epochs trained\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / max(1, batch_count)\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_acc, val_loss, val_miou, _, _ = validate_model(model, val_loader, criterion, device)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_mious.append(val_miou)\n",
    "\n",
    "        epochs_trained = epoch + 1  # Update epochs trained\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch < 10:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_epoch_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}, Val mIoU: {val_miou:.4f}\")\n",
    "\n",
    "    print(f\"Training completed after {epochs_trained} epochs\")\n",
    "    return model, train_losses, val_accuracies, val_losses, val_mious, epochs_trained\n",
    "\n",
    "\n",
    "def predict_with_dctu(model, data_loader, device, dynamic_weights):\n",
    "    \"\"\"Predict with DCTU-based uncertainty estimation\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    image_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, _, filenames = batch\n",
    "            else:\n",
    "                images, _ = batch\n",
    "                filenames = [f\"batch_image_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Compute DCTU score for each image in the batch\n",
    "            batch_dctu_scores = []\n",
    "            for i in range(probs.size(0)):\n",
    "                dctu_score = compute_dctu_score(probs[i], dynamic_weights)\n",
    "                batch_dctu_scores.append(dctu_score)\n",
    "\n",
    "            predictions.extend(probs.cpu())\n",
    "            uncertainties.extend(batch_dctu_scores)\n",
    "\n",
    "            if isinstance(filenames, (list, tuple)):\n",
    "                image_filenames.extend(filenames)\n",
    "            else:\n",
    "                image_filenames.append(filenames)\n",
    "\n",
    "    return predictions, uncertainties, image_filenames\n",
    "\n",
    "\n",
    "\n",
    "def perform_sample_selection_dcau_with_gamma(model, pool_image_dir, pool_label_dir, target_image_dir,\n",
    "                                           target_label_dir, selected_samples_dir, samples_per_iteration,\n",
    "                                           device, iteration, val_loader, batch_size=2, alpha=0.5, gamma=0.5):\n",
    "    \"\"\"\n",
    "    DCAU-based Sample Selection with Gamma Parameter (Paper Implementation)\n",
    "    \n",
    "    Args:\n",
    "        gamma: Scaling parameter for adaptive thresholding (default 0.5 as in paper)\n",
    "        alpha: Exponent for performance gap weighting (default 0.5 as in paper)\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- DCAU Sample Selection (γ={gamma}, α={alpha}) for Iteration {iteration + 1} ---\")\n",
    "\n",
    "    # Step 1: Compute class performance gaps\n",
    "    print(\"Computing class performance gaps...\")\n",
    "    class_gaps = compute_class_performance_gaps(model, val_loader, device)\n",
    "\n",
    "    # Step 2: Compute dynamic weights using paper's approach\n",
    "    dynamic_weights = compute_dynamic_weights(class_gaps, alpha, \n",
    "                                            use_softer_weighting=False,  # Use paper's approach\n",
    "                                            regularize=False)  # Use paper's approach\n",
    "\n",
    "    print(\"Class Performance Analysis:\")\n",
    "    for i, (gap, weight) in enumerate(zip(class_gaps, dynamic_weights)):\n",
    "        print(f\"  {class_names[i]}: Gap={gap:.4f}, Weight={weight:.4f}\")\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(selected_samples_dir, exist_ok=True)\n",
    "    selected_images_dir = os.path.join(selected_samples_dir, 'images')\n",
    "    selected_labels_dir = os.path.join(selected_samples_dir, 'labels')\n",
    "    os.makedirs(selected_images_dir, exist_ok=True)\n",
    "    os.makedirs(selected_labels_dir, exist_ok=True)\n",
    "\n",
    "    # Get pool samples\n",
    "    pool_files = [f for f in os.listdir(pool_image_dir) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "    print(f\"Available pool samples: {len(pool_files)}\")\n",
    "\n",
    "    if len(pool_files) == 0:\n",
    "        print(\"No samples available in pool!\")\n",
    "        return 0, []\n",
    "\n",
    "    # Create pool dataset and loader\n",
    "    pool_dataset = ValidationDataset(pool_image_dir, pool_label_dir)\n",
    "    pool_loader = create_safe_dataloader(pool_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Step 3: Compute DCAU scores for all pool samples\n",
    "    print(\"Computing DCAU scores...\")\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    image_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, _, filenames = batch\n",
    "            else:\n",
    "                images, _ = batch\n",
    "                filenames = [f\"batch_image_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Compute DCAU score for each image using paper's method\n",
    "            batch_dcau_scores = []\n",
    "            for i in range(probs.size(0)):\n",
    "                dcau_score = compute_dcau_score(probs[i], dynamic_weights)\n",
    "                batch_dcau_scores.append(dcau_score)\n",
    "\n",
    "            uncertainties.extend(batch_dcau_scores)\n",
    "            \n",
    "            if isinstance(filenames, (list, tuple)):\n",
    "                image_filenames.extend(filenames)\n",
    "            else:\n",
    "                image_filenames.append(filenames)\n",
    "\n",
    "    # Step 4: Apply adaptive thresholding with gamma\n",
    "    filtered_indices, threshold = apply_adaptive_thresholding(uncertainties, gamma)\n",
    "    \n",
    "    if len(filtered_indices) == 0:\n",
    "        print(f\"⚠️ No samples passed the adaptive threshold (γ={gamma}). Using top samples instead.\")\n",
    "        # Fall back to top-k selection\n",
    "        uncertainty_pairs = list(zip(uncertainties, image_filenames, range(len(uncertainties))))\n",
    "        uncertainty_pairs.sort(key=lambda x: x[0].item() if torch.is_tensor(x[0]) else x[0], reverse=True)\n",
    "        filtered_indices = [idx for _, _, idx in uncertainty_pairs[:samples_per_iteration]]\n",
    "    \n",
    "    # Step 5: Select top-K from filtered samples\n",
    "    filtered_uncertainties = [uncertainties[i] for i in filtered_indices]\n",
    "    filtered_filenames = [image_filenames[i] for i in filtered_indices]\n",
    "    \n",
    "    # Sort filtered samples by uncertainty and select top-K\n",
    "    filtered_pairs = list(zip(filtered_uncertainties, filtered_filenames))\n",
    "    filtered_pairs.sort(key=lambda x: x[0].item() if torch.is_tensor(x[0]) else x[0], reverse=True)\n",
    "    \n",
    "    # Take top-K from filtered samples\n",
    "    final_samples = min(samples_per_iteration, len(filtered_pairs))\n",
    "    selected_files = [filename for _, filename in filtered_pairs[:final_samples]]\n",
    "    selected_uncertainties = [unc for unc, _ in filtered_pairs[:final_samples]]\n",
    "\n",
    "    print(f\"Top 5 DCAU scores: {[u.item() if torch.is_tensor(u) else u for u in selected_uncertainties[:5]]}\")\n",
    "\n",
    "    # Step 6: Move selected samples (rest of function same as original)\n",
    "    # Get already existing files to avoid duplicates\n",
    "    existing_train_files = set()\n",
    "    if os.path.exists(target_image_dir):\n",
    "        existing_train_files = set([f for f in os.listdir(target_image_dir) \n",
    "                                  if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    # Move selected samples\n",
    "    moved_count = 0\n",
    "    successfully_moved = []\n",
    "    selection_log = []\n",
    "\n",
    "    for i, filename in enumerate(selected_files):\n",
    "        if filename in existing_train_files:\n",
    "            continue\n",
    "\n",
    "        # Source and destination paths\n",
    "        src_image = os.path.join(pool_image_dir, filename)\n",
    "        src_label = os.path.join(pool_label_dir, filename)\n",
    "        dst_image = os.path.join(target_image_dir, filename)\n",
    "        dst_label = os.path.join(target_label_dir, filename)\n",
    "        sel_image = os.path.join(selected_images_dir, filename)\n",
    "        sel_label = os.path.join(selected_labels_dir, filename)\n",
    "\n",
    "        try:\n",
    "            if not os.path.exists(src_image) or not os.path.exists(src_label):\n",
    "                continue\n",
    "\n",
    "            # Copy to selected samples directory\n",
    "            shutil.copy2(src_image, sel_image)\n",
    "            shutil.copy2(src_label, sel_label)\n",
    "\n",
    "            # Move to training directory\n",
    "            shutil.move(src_image, dst_image)\n",
    "            shutil.move(src_label, dst_label)\n",
    "\n",
    "            moved_count += 1\n",
    "            successfully_moved.append(filename)\n",
    "\n",
    "            # Log selection details\n",
    "            uncertainty_score = selected_uncertainties[i]\n",
    "            unc_value = uncertainty_score.item() if torch.is_tensor(uncertainty_score) else uncertainty_score\n",
    "\n",
    "            selection_log.append({\n",
    "                'filename': filename,\n",
    "                'dcau_score': unc_value,\n",
    "                'threshold': threshold,\n",
    "                'iteration': iteration + 1,\n",
    "                'alpha': alpha,\n",
    "                'gamma': gamma,\n",
    "                'selection_method': 'DCAU_with_Gamma'\n",
    "            })\n",
    "\n",
    "            print(f\"✅ Moved: {filename} (DCAU score: {unc_value:.4f})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to move {filename}: {e}\")\n",
    "\n",
    "    # Save selection log with gamma info\n",
    "    if selection_log:\n",
    "        log_df = pd.DataFrame(selection_log)\n",
    "        log_path = os.path.join(selected_samples_dir, f'dcau_gamma_selection_log_iteration_{iteration + 1}.csv')\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "        print(f\"✅ DCAU-Gamma selection log saved: {log_path}\")\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n--- DCAU-Gamma Selection Summary ---\")\n",
    "    print(f\"Gamma (γ): {gamma}\")\n",
    "    print(f\"Alpha (α): {alpha}\")\n",
    "    print(f\"Adaptive threshold: {threshold:.4f}\")\n",
    "    print(f\"Successfully moved: {moved_count}\")\n",
    "\n",
    "    remaining_pool = len([f for f in os.listdir(pool_image_dir) \n",
    "                         if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "    print(f\"Remaining in pool: {remaining_pool}\")\n",
    "\n",
    "    return moved_count, successfully_moved\n",
    "def create_test_prediction_heatmaps(model, test_loader, device, save_dir, iteration, class_names):\n",
    "    \"\"\"Create comprehensive test prediction heatmaps and visualizations\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Create subdirectory for test predictions\n",
    "    test_pred_dir = os.path.join(save_dir, 'test_predictions')\n",
    "    os.makedirs(test_pred_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Class-wise confidence distribution\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    class_confidences = [[] for _ in range(len(class_names))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if batch_idx >= 20:  # Limit to first 10 batches\n",
    "                break\n",
    "\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Collect confidence scores for each class\n",
    "            for cls in range(len(class_names)):\n",
    "                class_prob = probs[:, cls, :, :].cpu().numpy()\n",
    "                class_confidences[cls].extend(class_prob.flatten())\n",
    "\n",
    "    # Plot confidence distributions\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if i < len(axes) and class_confidences[i]:\n",
    "            conf_array = np.array(class_confidences[i])\n",
    "            axes[i].hist(conf_array, bins=50, alpha=0.7, color=plt.cm.tab10(i))\n",
    "            axes[i].set_title(f'{class_name}\\nMean: {conf_array.mean():.3f}', fontweight='bold')\n",
    "            axes[i].set_xlabel('Confidence Score')\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Test Set Class Confidence Distributions - Iteration {iteration}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(test_pred_dir, f'confidence_distributions_iter_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Sample predictions visualization\n",
    "    model.eval()\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if sample_count >= 20:  # Show 10 samples\n",
    "                break\n",
    "\n",
    "            if len(batch) == 3:\n",
    "                images, targets, filenames = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "                filenames = [f\"sample_{batch_idx}_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            for i in range(min(2, images.size(0))):  # Max 2 per batch\n",
    "                if sample_count >= 15:\n",
    "                    break\n",
    "\n",
    "                # Create subplot for this sample\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Original image\n",
    "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                axes[0].imshow(img)\n",
    "                axes[0].set_title('Original Image')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                # Ground truth\n",
    "                gt = targets[i].cpu().numpy()\n",
    "                gt_colored = apply_color_map(gt, COLOR_MAP)\n",
    "                axes[1].imshow(gt_colored)\n",
    "                axes[1].set_title('Ground Truth')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # Prediction\n",
    "                pred = predictions[i].cpu().numpy()\n",
    "                pred_colored = apply_color_map(pred, COLOR_MAP)\n",
    "                im2 = axes[2].imshow(pred_colored)\n",
    "                axes[2].set_title('Prediction')\n",
    "                axes[2].axis('off')\n",
    "\n",
    "                # Legend\n",
    "                legend_elements = [Patch(facecolor=np.array(COLOR_MAP[i])/255.0, label=class_names[i]) for i in range(len(class_names))]\n",
    "                fig.legend(handles=legend_elements, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "                filename = filenames[i] if isinstance(filenames[i], str) else f\"sample_{sample_count}\"\n",
    "                plt.suptitle(f'Test Sample: {filename} - Iteration {iteration}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(test_pred_dir, f'sample_{sample_count}_iter_{iteration}.png'),\n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "                sample_count += 1\n",
    "\n",
    "\n",
    "def verify_data_consistency(image_dir, label_dir, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Verify that images and labels are properly paired\"\"\"\n",
    "    if not os.path.exists(image_dir) or not os.path.exists(label_dir):\n",
    "        print(f\" {dataset_name}: Directories not found\")\n",
    "        return False\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "    label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    print(f\"{dataset_name}: {len(image_files)} images, {len(label_files)} labels\")\n",
    "\n",
    "    if len(image_files) != len(label_files):\n",
    "        print(f\" {dataset_name}: Mismatch in number of images and labels\")\n",
    "        return False\n",
    "\n",
    "    # Check if files match\n",
    "    missing_pairs = []\n",
    "    for img_file in image_files:\n",
    "        if img_file not in label_files:\n",
    "            missing_pairs.append(img_file)\n",
    "\n",
    "    if missing_pairs:\n",
    "        print(f\" {dataset_name}: Missing label files: {missing_pairs[:5]}...\")\n",
    "        return False\n",
    "\n",
    "    print(f\"✓ {dataset_name}: Data consistency verified\")\n",
    "    return True\n",
    "\n",
    "def plot_metrics(metrics_history, save_dir, iteration):\n",
    "    \"\"\"Plot training metrics with improved visualization\"\"\"\n",
    "    if not metrics_history:\n",
    "        return\n",
    "\n",
    "    # Create metrics directory\n",
    "    metrics_dir = os.path.join(save_dir, 'metrics')\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    # Plot comprehensive metrics\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    iterations = list(range(1, len(metrics_history) + 1))\n",
    "\n",
    "    # Extract metrics\n",
    "    train_losses = [m.get('train_loss', 0) for m in metrics_history]\n",
    "    val_accuracies = [m.get('val_accuracy', 0) for m in metrics_history]\n",
    "    val_losses = [m.get('val_loss', 0) for m in metrics_history]\n",
    "    val_mious = [m.get('val_miou', 0) for m in metrics_history]\n",
    "    samples_added = [m.get('samples_added', 0) for m in metrics_history]\n",
    "    epochs_trained = [m.get('epochs_trained', 0) for m in metrics_history]\n",
    "\n",
    "    # Plot 1: Training Loss\n",
    "    axes[0, 0].plot(iterations, train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Validation Accuracy\n",
    "    axes[0, 1].plot(iterations, val_accuracies, 'g-o', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Validation Loss\n",
    "    axes[0, 2].plot(iterations, val_losses, 'r-o', linewidth=2, markersize=6)\n",
    "    axes[0, 2].set_title('Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Loss')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 4: Validation mIoU\n",
    "    axes[1, 0].plot(iterations, val_mious, 'purple', marker='o', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_title('Validation mIoU', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('mIoU')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 5: Samples Added\n",
    "    axes[1, 1].bar(iterations, samples_added, color='orange', alpha=0.7)\n",
    "    axes[1, 1].set_title('Samples Added per Iteration', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Iteration')\n",
    "    axes[1, 1].set_ylabel('Number of Samples')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 6: Epochs Trained\n",
    "    axes[1, 2].bar(iterations, epochs_trained, color='brown', alpha=0.7)\n",
    "    axes[1, 2].set_title('Epochs Trained per Iteration', fontsize=14, fontweight='bold')\n",
    "    axes[1, 2].set_xlabel('Iteration')\n",
    "    axes[1, 2].set_ylabel('Number of Epochs')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Active Learning Progress - Up to Iteration {iteration}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f'metrics_iteration_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Additional plot: Combined accuracy and mIoU\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    ax.plot(iterations, val_accuracies, 'g-o', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "    ax.plot(iterations, val_mious, 'purple', marker='s', label='Validation mIoU', linewidth=2, markersize=6)\n",
    "    ax.set_title('Model Performance Over Iterations', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f'performance_comparison_iteration_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def save_detailed_results(results, save_dir, iteration):\n",
    "    \"\"\"Save detailed results to CSV and create summary report\"\"\"\n",
    "    results_dir = os.path.join(save_dir, 'results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Save detailed metrics\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    metrics_path = os.path.join(results_dir, f'detailed_metrics_iteration_{iteration}.csv')\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    # Create summary report\n",
    "    summary_path = os.path.join(results_dir, f'summary_report_iteration_{iteration}.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(f\"Active Learning Summary - Iteration {iteration}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        if results:\n",
    "            latest = results[-1]\n",
    "            f.write(f\"Current Performance:\\n\")\n",
    "            f.write(f\"  - Validation Accuracy: {latest.get('val_accuracy', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Validation mIoU: {latest.get('val_miou', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Training Loss: {latest.get('train_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Validation Loss: {latest.get('val_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Samples Added: {latest.get('samples_added', 0)}\\n\")\n",
    "            f.write(f\"  - Epochs Trained: {latest.get('epochs_trained', 0)}\\n\\n\")\n",
    "\n",
    "            # Class-wise performance\n",
    "            if 'class_accuracies' in latest:\n",
    "                f.write(\"Class-wise Accuracies:\\n\")\n",
    "                for i, acc in enumerate(latest['class_accuracies']):\n",
    "                    f.write(f\"  - {class_names[i]}: {acc:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            if 'class_ious' in latest:\n",
    "                f.write(\"Class-wise IoUs:\\n\")\n",
    "                for i, iou in enumerate(latest['class_ious']):\n",
    "                    if not np.isnan(iou):\n",
    "                        f.write(f\"  - {class_names[i]}: {iou:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        # Progress summary\n",
    "        if len(results) > 1:\n",
    "            f.write(\"Progress Summary:\\n\")\n",
    "            first_acc = results[0].get('val_accuracy', 0)\n",
    "            latest_acc = results[-1].get('val_accuracy', 0)\n",
    "            acc_improvement = latest_acc - first_acc\n",
    "\n",
    "            first_miou = results[0].get('val_miou', 0)\n",
    "            latest_miou = results[-1].get('val_miou', 0)\n",
    "            miou_improvement = latest_miou - first_miou\n",
    "\n",
    "            f.write(f\"  - Accuracy Improvement: {acc_improvement:+.4f}\\n\")\n",
    "            f.write(f\"  - mIoU Improvement: {miou_improvement:+.4f}\\n\")\n",
    "\n",
    "            total_samples = sum(r.get('samples_added', 0) for r in results)\n",
    "            f.write(f\"  - Total Samples Added: {total_samples}\\n\")\n",
    "\n",
    "    print(f\"✓ Detailed results saved: {results_dir}\")\n",
    "\n",
    "def calculate_class_weights(train_images_dir, train_labels_dir, num_classes=9):\n",
    "    \"\"\"Calculate class weights based on pixel frequency in training data\"\"\"\n",
    "    print(\"Calculating class weights...\")\n",
    "\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    total_pixels = 0\n",
    "\n",
    "    label_files = [f for f in os.listdir(train_labels_dir) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "\n",
    "    for label_file in label_files:\n",
    "        label_path = os.path.join(train_labels_dir, label_file)\n",
    "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "            label = np.clip(label, 0, num_classes-1)\n",
    "\n",
    "            # Count pixels for each class\n",
    "            for cls in range(num_classes):\n",
    "                class_counts[cls] += np.sum(label == cls)\n",
    "            total_pixels += label.size\n",
    "\n",
    "    # Calculate weights (inverse frequency)\n",
    "    class_weights = total_pixels / (num_classes * class_counts + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "    # Normalize weights\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "\n",
    "    print(\"Class weights:\")\n",
    "    for i, weight in enumerate(class_weights):\n",
    "        print(f\"  {class_names[i]}: {weight:.4f}\")\n",
    "\n",
    "    return torch.FloatTensor(class_weights)\n",
    "def main():\n",
    "    \"\"\"Main active learning pipeline\"\"\"\n",
    "\n",
    "    # System setup\n",
    "    print(\"ACTIVE LEARNING PIPELINE FOR SEMANTIC SEGMENTATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    global OPTIMAL_WORKERS\n",
    "    OPTIMAL_WORKERS = check_system_capabilities()\n",
    "\n",
    "    # Configure device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "    # Directory setup\n",
    "    BASE_DIR = r\"E:\\hemanth\\data\\data\"\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, \"results_dcau_gamma_0.5_\")\n",
    "\n",
    "    # Data directories\n",
    "    TRAIN_IMAGES = os.path.join(BASE_DIR, \"train_data\" )\n",
    "    TRAIN_LABELS = os.path.join(BASE_DIR, \"train_labels\" )\n",
    "    POOL_IMAGES = os.path.join(BASE_DIR, \"Unlabeled_data\")\n",
    "    POOL_LABELS = os.path.join(BASE_DIR, \"Validation_labels\")\n",
    "    VAL_IMAGES = os.path.join(BASE_DIR, \"val_img\")\n",
    "    VAL_LABELS = os.path.join(BASE_DIR, \"val_lab\")\n",
    "    TEST_IMAGES = os.path.join(BASE_DIR, \"test_img\")\n",
    "    TEST_LABELS = os.path.join(BASE_DIR, \"test_lab\")\n",
    "\n",
    "    # Create directories\n",
    "    for dir_path in [RESULTS_DIR, TRAIN_IMAGES, TRAIN_LABELS, POOL_IMAGES, POOL_LABELS,\n",
    "                     VAL_IMAGES, VAL_LABELS, TEST_IMAGES, TEST_LABELS]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Verify data consistency\n",
    "    print(\"\\n--- Data Verification ---\")\n",
    "    train_ok = verify_data_consistency(TRAIN_IMAGES, TRAIN_LABELS, \"Training\")\n",
    "    pool_ok = verify_data_consistency(POOL_IMAGES, POOL_LABELS, \"Pool\")\n",
    "    val_ok = verify_data_consistency(VAL_IMAGES, VAL_LABELS, \"Validation\")\n",
    "    test_ok = verify_data_consistency(TEST_IMAGES, TEST_LABELS, \"Test\")\n",
    "\n",
    "    if not all([train_ok, pool_ok, val_ok, test_ok]):\n",
    "        print(\"Data consistency issues found. Please check your data directories.\")\n",
    "        return\n",
    "\n",
    "    # Active learning parameters\n",
    "    MAX_ITERATIONS = 10\n",
    "    SAMPLES_PER_ITERATION = 100\n",
    "    EPOCHS_PER_ITERATION = 80\n",
    "    epochs_trained = EPOCHS_PER_ITERATION\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 0.0001\n",
    "    GAMMA = 0.5\n",
    "    ALPHA = 0.5\n",
    "    # PATIENCE = 20\n",
    "    # MIN_DELTA = 0.001\n",
    "\n",
    "    print(f\"\\n--- Active Learning Configuration ---\")\n",
    "    print(f\"Max Iterations: {MAX_ITERATIONS}\")\n",
    "    print(f\"Samples per Iteration: {SAMPLES_PER_ITERATION}\")\n",
    "    print(f\"Epochs per Iteration: {EPOCHS_PER_ITERATION}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    metrics_history = []\n",
    "\n",
    "    # Create validation dataset (remains constant)\n",
    "    val_dataset = SegmentationDataset(VAL_IMAGES, VAL_LABELS)\n",
    "    val_loader = create_safe_dataloader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Create test dataset (for evaluation)\n",
    "    test_dataset = ValidationDataset(TEST_IMAGES, TEST_LABELS)\n",
    "    test_loader = create_safe_dataloader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"\\nValidation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    # Active learning loop\n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ACTIVE LEARNING ITERATION {iteration + 1}/{MAX_ITERATIONS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Create iteration directory\n",
    "        iteration_dir = os.path.join(RESULTS_DIR, f\"iteration_{iteration + 1}\")\n",
    "        os.makedirs(iteration_dir, exist_ok=True)\n",
    "\n",
    "        # Check if we have training data\n",
    "        train_files = [f for f in os.listdir(TRAIN_IMAGES) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "        if len(train_files) == 0:\n",
    "            print(\" No training samples available. Skipping iteration.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Current training samples: {len(train_files)}\")\n",
    "\n",
    "        # Create training dataset and loader\n",
    "        train_dataset = SegmentationDataset(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "        train_loader = create_safe_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        # Initialize model\n",
    "        model = UNet(num_classes=num_classes)\n",
    "        print(\"\\n--- Calculating Initial Class Weights ---\")\n",
    "        class_weights = calculate_class_weights(TRAIN_IMAGES, TRAIN_LABELS, num_classes)\n",
    "\n",
    "        class_weights = class_weights.to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "       # criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        # Train model\n",
    "        print(f\"\\n--- Training Model ---\")\n",
    "        start_time = time.time()\n",
    "        model, train_losses, val_accuracies, val_losses, val_mious, epochs_trained = train_model_with_validation(\n",
    "         train_loader, val_loader, model, criterion, optimizer,\n",
    "         EPOCHS_PER_ITERATION, device )\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "        # Save model\n",
    "        model_path = save_model(model, iteration_dir, iteration + 1)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        print(f\"\\n--- Test Evaluation ---\")\n",
    "        test_acc, test_loss, test_miou, test_class_ious, test_class_accuracies = validate_model(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Test mIoU: {test_miou:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Create test predictions and visualizations\n",
    "        create_test_prediction_heatmaps(model, test_loader, device, iteration_dir, iteration + 1, class_names)\n",
    "\n",
    "        # Store metrics\n",
    "        iteration_metrics = {\n",
    "            'iteration': iteration + 1,\n",
    "            'train_loss': train_losses[-1] if train_losses else 0,\n",
    "            'val_accuracy': val_accuracies[-1] if val_accuracies else 0,\n",
    "            'val_loss': val_losses[-1] if val_losses else 0,\n",
    "            'val_miou': val_mious[-1] if val_mious else 0,\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_miou': test_miou,\n",
    "            'epochs_trained': epochs_trained,\n",
    "            'class_accuracies': test_class_accuracies,\n",
    "            'class_ious': test_class_ious.tolist() if hasattr(test_class_ious, 'tolist') else test_class_ious,\n",
    "            'class_weights': class_weights.cpu().tolist(),\n",
    "            'samples_added': 0  # Will be updated after sample selection\n",
    "        }\n",
    "\n",
    "        # Sample selection for next iteration (if not last iteration)\n",
    "        if iteration < MAX_ITERATIONS - 1:\n",
    "            print(f\"\\n--- Sample Selection ---\")\n",
    "            selected_samples_dir = os.path.join(iteration_dir, \"selected_samples\")\n",
    "            samples_added, selected_files = perform_sample_selection_dcau_with_gamma(model, POOL_IMAGES, POOL_LABELS, TRAIN_IMAGES, TRAIN_LABELS,\n",
    "              selected_samples_dir, SAMPLES_PER_ITERATION, device, iteration, val_loader, \n",
    "               BATCH_SIZE, alpha=0.5, gamma=0.5  # Add gamma parameter here\n",
    "                     )\n",
    "\n",
    "\n",
    "            iteration_metrics['samples_added'] = samples_added\n",
    "\n",
    "            if samples_added == 0:\n",
    "                print(\" No samples could be added. Stopping active learning.\")\n",
    "                break\n",
    "\n",
    "        metrics_history.append(iteration_metrics)\n",
    "\n",
    "        # Plot and save results\n",
    "        plot_metrics(metrics_history, RESULTS_DIR, iteration + 1)\n",
    "        save_detailed_results(metrics_history, RESULTS_DIR, iteration + 1)\n",
    "\n",
    "        # Memory cleanup\n",
    "        del model, train_loader, train_dataset\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"\\n--- Iteration {iteration + 1} Complete ---\")\n",
    "        print(f\"Training samples: {len(train_files)}\")\n",
    "        print(f\"Validation Accuracy: {iteration_metrics['val_accuracy']:.4f}\")\n",
    "        print(f\"Test Accuracy: {iteration_metrics['test_accuracy']:.4f}\")\n",
    "        print(f\"Test mIoU: {iteration_metrics['test_miou']:.4f}\")\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ACTIVE LEARNING COMPLETED\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if metrics_history:\n",
    "        print(f\"Total iterations: {len(metrics_history)}\")\n",
    "        print(f\"Final test accuracy: {metrics_history[-1]['test_accuracy']:.4f}\")\n",
    "        print(f\"Final test mIoU: {metrics_history[-1]['test_miou']:.4f}\")\n",
    "\n",
    "        # Calculate improvement\n",
    "        if len(metrics_history) > 1:\n",
    "            acc_improvement = metrics_history[-1]['test_accuracy'] - metrics_history[0]['test_accuracy']\n",
    "            miou_improvement = metrics_history[-1]['test_miou'] - metrics_history[0]['test_miou']\n",
    "            print(f\"Accuracy improvement: {acc_improvement:+.4f}\")\n",
    "            print(f\"mIoU improvement: {miou_improvement:+.4f}\")\n",
    "\n",
    "    print(f\"\\nResults saved in: {RESULTS_DIR}\")\n",
    "    print(\"Active learning pipeline completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939e06e-dbbe-46f7-bb64-46e0bf8a4091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
