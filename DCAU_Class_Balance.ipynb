{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a6002-93ae-407f-a354-072871b124bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04bd5d3-f42d-4427-86f6-c2d8734fd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCAU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867fe61-a24a-4d78-b3f6-9faef974fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE LEARNING PIPELINE FOR SEMANTIC SEGMENTATION\n",
      "============================================================\n",
      "============================================================\n",
      "SYSTEM CAPABILITY CHECK\n",
      "============================================================\n",
      "Operating System: Windows 11\n",
      "Physical cores: 24\n",
      "Logical cores: 32\n",
      "Total RAM: 127.72 GB\n",
      "CUDA available: Yes, 1 GPU(s)\n",
      "Recommended num_workers: 0\n",
      "\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "GPU Memory: 12.0 GB\n",
      "\n",
      "--- Data Verification ---\n",
      "Training: 512 images, 512 labels\n",
      "✓ Training: Data consistency verified\n",
      "Pool: 2414 images, 2414 labels\n",
      "✓ Pool: Data consistency verified\n",
      "Validation: 250 images, 250 labels\n",
      "✓ Validation: Data consistency verified\n",
      "Test: 250 images, 250 labels\n",
      "✓ Test: Data consistency verified\n",
      "\n",
      "--- Active Learning Configuration ---\n",
      "Max Iterations: 15\n",
      "Samples per Iteration: 25\n",
      "Epochs per Iteration: 25\n",
      "Batch Size: 8\n",
      "Learning Rate: 0.0001\n",
      "\n",
      "Validation samples: 250\n",
      "Test samples: 250\n",
      "\n",
      "============================================================\n",
      "ACTIVE LEARNING ITERATION 1/15\n",
      "============================================================\n",
      "Current training samples: 512\n",
      "\n",
      "--- Calculating Initial Class Weights ---\n",
      "Calculating class weights...\n",
      "Class weights:\n",
      "  Background: 7.4063\n",
      "  Bareland: 0.7718\n",
      "  Rangeland: 0.0549\n",
      "  Developed Space: 0.0630\n",
      "  Road: 0.1869\n",
      "  Tree: 0.0971\n",
      "  Water: 0.1121\n",
      "  Agriculture Land: 0.1809\n",
      "  Building: 0.1270\n",
      "\n",
      "--- Training Model ---\n",
      "Starting training for 25 epochs...\n",
      "Epoch 1/25 - Train Loss: 1.6797, Val Acc: 0.3131, Val mIoU: 0.2141\n",
      "Epoch 2/25 - Train Loss: 1.4323, Val Acc: 0.4321, Val mIoU: 0.2902\n",
      "Epoch 3/25 - Train Loss: 1.3513, Val Acc: 0.4790, Val mIoU: 0.3379\n",
      "Epoch 4/25 - Train Loss: 1.3143, Val Acc: 0.4627, Val mIoU: 0.3080\n",
      "Epoch 5/25 - Train Loss: 1.2660, Val Acc: 0.4746, Val mIoU: 0.3234\n",
      "Epoch 6/25 - Train Loss: 1.2565, Val Acc: 0.4967, Val mIoU: 0.3642\n",
      "Epoch 7/25 - Train Loss: 1.2047, Val Acc: 0.5395, Val mIoU: 0.3538\n",
      "Epoch 8/25 - Train Loss: 1.1856, Val Acc: 0.5203, Val mIoU: 0.3827\n",
      "Epoch 9/25 - Train Loss: 1.1613, Val Acc: 0.5133, Val mIoU: 0.3401\n",
      "Epoch 10/25 - Train Loss: 1.1468, Val Acc: 0.5279, Val mIoU: 0.3536\n",
      "Epoch 15/25 - Train Loss: 1.0593, Val Acc: 0.5242, Val mIoU: 0.3525\n",
      "Epoch 20/25 - Train Loss: 0.9935, Val Acc: 0.5829, Val mIoU: 0.3769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## DCAU\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import platform\n",
    "import sys\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_system_capabilities():\n",
    "    \"\"\"Check system capabilities to determine optimal num_workers\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"SYSTEM CAPABILITY CHECK\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    logical_cores = psutil.cpu_count(logical=True)\n",
    "    physical_cores = psutil.cpu_count(logical=False)\n",
    "\n",
    "    print(f\"Operating System: {platform.system()} {platform.release()}\")\n",
    "    print(f\"Physical cores: {physical_cores}\")\n",
    "    print(f\"Logical cores: {logical_cores}\")\n",
    "\n",
    "    memory = psutil.virtual_memory()\n",
    "    total_memory_gb = memory.total / (1024**3)\n",
    "    print(f\"Total RAM: {total_memory_gb:.2f} GB\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        print(f\"CUDA available: Yes, {gpu_count} GPU(s)\")\n",
    "    else:\n",
    "        print(\"CUDA available: No\")\n",
    "\n",
    "    # Conservative approach for Windows\n",
    "    recommended_workers = 0 if platform.system() == \"Windows\" else min(2, physical_cores)\n",
    "    print(f\"Recommended num_workers: {recommended_workers}\")\n",
    "\n",
    "    return recommended_workers\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Class Names\n",
    "class_names = [\n",
    "    \"Background\", \"Bareland\", \"Rangeland\", \"Developed Space\", \"Road\",\n",
    "    \"Tree\", \"Water\", \"Agriculture Land\", \"Building\"\n",
    "]\n",
    "num_classes = len(class_names)\n",
    "COLOR_MAP = {\n",
    "    0: (0, 0, 0),        # Background - Black\n",
    "    1: (128, 0, 0),      # Bareland - Maroon\n",
    "    2: (0, 255, 36),     # Rangeland - Green\n",
    "    3: (148, 148, 148),  # Developed Space - Gray\n",
    "    4: (255, 255, 255),  # Road - White\n",
    "    5: (34, 97, 38),     # Tree - Dark Green\n",
    "    6: (0, 69, 255),     # Water - Blue\n",
    "    7: (75, 181, 73),    # Agriculture Land - Light Green\n",
    "    8: (222, 31, 7)      # Building - Red\n",
    "}\n",
    "# UNet Model Definition\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(3, 64)\n",
    "        self.contracting_12 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_21 = self.conv_block(64, 128)\n",
    "        self.contracting_22 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_31 = self.conv_block(128, 256)\n",
    "        self.contracting_32 = nn.MaxPool2d(2, 2)\n",
    "        self.contracting_41 = self.conv_block(256, 512)\n",
    "        self.contracting_42 = nn.MaxPool2d(2, 2)\n",
    "        self.middle = self.conv_block(512, 1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(1024, 512, 3, 2, 1, 1)\n",
    "        self.expansive_12 = self.conv_block(1024, 512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(512, 256, 3, 2, 1, 1)\n",
    "        self.expansive_22 = self.conv_block(512, 256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "        self.expansive_32 = self.conv_block(256, 128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n",
    "        self.expansive_42 = self.conv_block(128, 64)\n",
    "        self.output = nn.Conv2d(64, num_classes, 3, 1, 1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.contracting_11(x)\n",
    "        p1 = self.contracting_12(c1)\n",
    "        c2 = self.contracting_21(p1)\n",
    "        p2 = self.contracting_22(c2)\n",
    "        c3 = self.contracting_31(p2)\n",
    "        p3 = self.contracting_32(c3)\n",
    "        c4 = self.contracting_41(p3)\n",
    "        p4 = self.contracting_42(c4)\n",
    "        middle = self.middle(p4)\n",
    "        u1 = self.expansive_11(middle)\n",
    "        u1 = self.expansive_12(torch.cat((u1, c4), dim=1))\n",
    "        u2 = self.expansive_21(u1)\n",
    "        u2 = self.expansive_22(torch.cat((u2, c3), dim=1))\n",
    "        u3 = self.expansive_31(u2)\n",
    "        u3 = self.expansive_32(torch.cat((u3, c2), dim=1))\n",
    "        u4 = self.expansive_41(u3)\n",
    "        u4 = self.expansive_42(torch.cat((u4, c1), dim=1))\n",
    "        output = self.output(u4)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "\n",
    "        # Load image (RGB)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "        # Load mask as GRAYSCALE (single channel)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Failed to load mask: {mask_path}\")\n",
    "\n",
    "        # Resize\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Convert image to tensor [C, H, W] and normalize\n",
    "        image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Convert mask to tensor [H, W] - NO channel dimension for segmentation masks\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        mask = torch.clamp(mask, 0, 8)  # Ensure valid class indices\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        self.has_labels = label_dir is not None\n",
    "\n",
    "        if self.has_labels:\n",
    "            self.label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "        else:\n",
    "            self.label_files = [None] * len(self.image_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        image_tensor = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        if self.has_labels and self.label_files[idx]:\n",
    "            label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
    "            if os.path.exists(label_path):\n",
    "                # Load label as GRAYSCALE\n",
    "                label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if label is not None:\n",
    "                    label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "                    label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "                    label_tensor = torch.clamp(label_tensor, 0, 8)\n",
    "                else:\n",
    "                    label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "            else:\n",
    "                label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "        else:\n",
    "            label_tensor = torch.zeros((512, 512), dtype=torch.long)\n",
    "\n",
    "        return image_tensor, label_tensor, self.image_files[idx]\n",
    "\n",
    "def apply_color_map(mask, color_map):\n",
    "    \"\"\"Apply color map to segmentation mask\"\"\"\n",
    "    h, w = mask.shape\n",
    "    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in color_map.items():\n",
    "        colored_mask[mask == class_id] = color\n",
    "\n",
    "    return colored_mask\n",
    "\n",
    "def create_safe_dataloader(dataset, batch_size, shuffle=False, num_workers=None):\n",
    "    \"\"\"Create a DataLoader with safe num_workers handling\"\"\"\n",
    "    if num_workers is None:\n",
    "        num_workers = OPTIMAL_WORKERS\n",
    "\n",
    "    if platform.system() == \"Windows\":\n",
    "        num_workers = 0\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available() and num_workers == 0\n",
    "    )\n",
    "\n",
    "def compute_miou(preds, targets, num_classes=9):\n",
    "    \"\"\"Compute mean IoU and class-wise IoU\"\"\"\n",
    "    iou_per_class = np.zeros(num_classes)\n",
    "    preds = preds.flatten()\n",
    "    targets = targets.flatten()\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if (targets == cls).sum() == 0:\n",
    "            iou_per_class[cls] = np.nan\n",
    "            continue\n",
    "        iou_per_class[cls] = jaccard_score(targets == cls, preds == cls, zero_division=0)\n",
    "\n",
    "    return np.nanmean(iou_per_class), iou_per_class\n",
    "def compute_entropy(prob_map):\n",
    "    \"\"\"Compute pixel-wise entropy as uncertainty measure\"\"\"\n",
    "    entropy = -torch.sum(prob_map * torch.log(prob_map + 1e-10), dim=0)\n",
    "    return entropy\n",
    "\n",
    "def compute_class_performance_gaps(model, val_loader, device, num_classes=9):\n",
    "    \"\"\"Compute IoU-based performance gaps for each class with moderated weighting\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Calculate class-wise IoU and performance gaps\n",
    "    class_gaps = np.zeros(num_classes)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if (all_targets == cls).sum() == 0:\n",
    "            class_gaps[cls] = 0.1  # Minimum gap for classes without samples\n",
    "            continue\n",
    "\n",
    "        # Calculate IoU for this class\n",
    "        tp = np.sum((all_preds == cls) & (all_targets == cls))\n",
    "        fp = np.sum((all_preds == cls) & (all_targets != cls))\n",
    "        fn = np.sum((all_preds != cls) & (all_targets == cls))\n",
    "\n",
    "        if tp + fp + fn == 0:\n",
    "            iou = 1.0  # Perfect if no predictions or targets\n",
    "        else:\n",
    "            iou = tp / (tp + fp + fn)\n",
    "\n",
    "        # **CHANGE 1: Moderate the Weighting - Floor the gap**\n",
    "        class_gaps[cls] = max(0.1, 1.0 - iou)  # Floor the gap to prevent zero weights\n",
    "\n",
    "    return class_gaps\n",
    "\n",
    "\n",
    "def compute_dynamic_weights(class_gaps, alpha=1.0, use_softer_weighting=True, regularize=True):\n",
    "    \"\"\"Compute dynamic weights based on performance gaps with improvements\"\"\"\n",
    "\n",
    "    if use_softer_weighting:\n",
    "        # **CHANGE 2: Use softer weighting - less aggressive**\n",
    "        weighted_gaps = np.sqrt(class_gaps)  # Less aggressive than power\n",
    "    else:\n",
    "        # Apply exponential weighting (original approach)\n",
    "        weighted_gaps = np.power(class_gaps, alpha)\n",
    "\n",
    "    # Normalize to create probability distribution\n",
    "    total_weighted = np.sum(weighted_gaps)\n",
    "    if total_weighted == 0:\n",
    "        # If all gaps are zero, use uniform weighting\n",
    "        weights = np.ones(len(class_gaps)) / len(class_gaps)\n",
    "    else:\n",
    "        weights = weighted_gaps / total_weighted\n",
    "\n",
    "    if regularize:\n",
    "        # **CHANGE 4: Regularized Class Weights - Prevent extreme weighting**\n",
    "        weights = np.clip(weights, a_min=0.1/len(class_gaps), a_max=2.0/len(class_gaps))\n",
    "        # Renormalize after clipping\n",
    "        weights = weights / weights.sum()\n",
    "\n",
    "    return weights\n",
    "\n",
    "def compute_hybrid_dctu_score(prob_map, dynamic_weights, entropy_weight=0.7, class_weight=0.3):\n",
    "    \"\"\"\n",
    "    **CHANGE 2: Hybrid Approach - Combine entropy and class-awareness**\n",
    "    Compute Hybrid DCTU score combining standard entropy and class-weighted uncertainty\n",
    "\n",
    "    Args:\n",
    "        prob_map: [C, H, W] probability map for each class\n",
    "        dynamic_weights: [C] weights for each class based on performance gaps\n",
    "        entropy_weight: Weight for standard entropy component\n",
    "        class_weight: Weight for class-weighted component\n",
    "\n",
    "    Returns:\n",
    "        hybrid_score: scalar uncertainty score for the image\n",
    "    \"\"\"\n",
    "    # Ensure weights are on the same device as prob_map\n",
    "    if torch.is_tensor(dynamic_weights):\n",
    "        weights = dynamic_weights.to(prob_map.device)\n",
    "    else:\n",
    "        weights = torch.tensor(dynamic_weights, dtype=prob_map.dtype, device=prob_map.device)\n",
    "\n",
    "    # 1. Standard entropy score\n",
    "    entropy_map = -torch.sum(prob_map * torch.log(prob_map + 1e-10), dim=0)  # [H, W]\n",
    "    entropy_score = torch.mean(entropy_map)\n",
    "\n",
    "    # 2. Class-weighted uncertainty score\n",
    "    weighted_entropy = torch.zeros_like(entropy_map)\n",
    "    for c in range(prob_map.size(0)):\n",
    "        # Weight entropy by class probability and dynamic weight\n",
    "        weighted_entropy += prob_map[c] * weights[c] * entropy_map\n",
    "    class_weighted_score = torch.mean(weighted_entropy)\n",
    "\n",
    "    # 3. Combine both scores\n",
    "    hybrid_score = entropy_weight * entropy_score + class_weight * class_weighted_score\n",
    "\n",
    "    return hybrid_score\n",
    "def distribute_samples_by_class(total_samples, class_weights, min_per_class=1):\n",
    "    \"\"\"\n",
    "    **CHANGE 3: Class Frequency Constraint**\n",
    "    Distribute samples ensuring minimum representation for all classes\n",
    "    \"\"\"\n",
    "    num_classes = len(class_weights)\n",
    "\n",
    "    # Reserve minimum samples per class\n",
    "    reserved_samples = min_per_class * num_classes\n",
    "    remaining_samples = max(0, total_samples - reserved_samples)\n",
    "\n",
    "    # Initialize with minimum samples per class\n",
    "    samples_per_class = np.full(num_classes, min_per_class)\n",
    "\n",
    "    # Distribute remaining samples based on weights\n",
    "    if remaining_samples > 0:\n",
    "        # Normalize weights for remaining samples\n",
    "        normalized_weights = class_weights / np.sum(class_weights)\n",
    "        additional_samples = (normalized_weights * remaining_samples).astype(int)\n",
    "\n",
    "        # Handle rounding errors\n",
    "        samples_allocated = np.sum(additional_samples)\n",
    "        if samples_allocated < remaining_samples:\n",
    "            # Add remaining samples to classes with highest fractional parts\n",
    "            fractional_parts = (normalized_weights * remaining_samples) - additional_samples\n",
    "            top_classes = np.argsort(fractional_parts)[-int(remaining_samples - samples_allocated):]\n",
    "            additional_samples[top_classes] += 1\n",
    "\n",
    "        samples_per_class += additional_samples\n",
    "\n",
    "    return samples_per_class\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model and return comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels = 0\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_pixels += targets.numel()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "    accuracy = total_correct / total_pixels if total_pixels > 0 else 0.0\n",
    "    avg_loss = total_loss / len(val_loader) if len(val_loader) > 0 else float('inf')\n",
    "\n",
    "    # Compute mIoU\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_targets = np.array(all_targets)\n",
    "    miou, class_ious = compute_miou(all_preds, all_targets)\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_accuracies = []\n",
    "    for cls in range(num_classes):\n",
    "        mask = (all_targets == cls)\n",
    "        if mask.sum() > 0:\n",
    "            class_acc = np.mean(all_preds[mask] == all_targets[mask])\n",
    "            class_accuracies.append(class_acc)\n",
    "        else:\n",
    "            class_accuracies.append(0.0)\n",
    "\n",
    "    return accuracy, avg_loss, miou, class_ious, class_accuracies\n",
    "\n",
    "def save_model(model, iteration_dir, iteration):\n",
    "    \"\"\"Save model with proper handling of DataParallel\"\"\"\n",
    "    model_path = os.path.join(iteration_dir, f'model_iteration_{iteration}.pth')\n",
    "\n",
    "    # Handle DataParallel model\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model_state = model.module.state_dict()\n",
    "    else:\n",
    "        model_state = model.state_dict()\n",
    "\n",
    "    # Save model state\n",
    "    torch.save({\n",
    "        'model_state_dict': model_state,\n",
    "        'iteration': iteration,\n",
    "        'num_classes': num_classes,\n",
    "        'model_type': 'UNet'\n",
    "    }, model_path)\n",
    "\n",
    "    print(f\"✓ Model saved: {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "def train_model_with_validation(train_loader, val_loader, model, criterion, optimizer,\n",
    "                               num_epochs, device):\n",
    "    \"\"\"Train model with validation and early stopping - returns epochs trained\"\"\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "   # early_stopping = EarlyStopping(patience=patience, min_delta=min_delta, restore_best_weights=True)\n",
    "\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "    val_mious = []\n",
    "\n",
    "  #  print(f\"Starting training with early stopping (patience={patience}, min_delta={min_delta})...\")\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "\n",
    "    epochs_trained = 0  # Track actual epochs trained\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / max(1, batch_count)\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_acc, val_loss, val_miou, _, _ = validate_model(model, val_loader, criterion, device)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_mious.append(val_miou)\n",
    "\n",
    "        epochs_trained = epoch + 1  # Update epochs trained\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch < 10:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_epoch_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_acc:.4f}, Val mIoU: {val_miou:.4f}\")\n",
    "\n",
    "    print(f\"Training completed after {epochs_trained} epochs\")\n",
    "    return model, train_losses, val_accuracies, val_losses, val_mious, epochs_trained\n",
    "\n",
    "\n",
    "def predict_with_dctu(model, data_loader, device, dynamic_weights):\n",
    "    \"\"\"Predict with DCTU-based uncertainty estimation\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    image_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, _, filenames = batch\n",
    "            else:\n",
    "                images, _ = batch\n",
    "                filenames = [f\"batch_image_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Compute DCTU score for each image in the batch\n",
    "            batch_dctu_scores = []\n",
    "            for i in range(probs.size(0)):\n",
    "                dctu_score = compute_dctu_score(probs[i], dynamic_weights)\n",
    "                batch_dctu_scores.append(dctu_score)\n",
    "\n",
    "            predictions.extend(probs.cpu())\n",
    "            uncertainties.extend(batch_dctu_scores)\n",
    "\n",
    "            if isinstance(filenames, (list, tuple)):\n",
    "                image_filenames.extend(filenames)\n",
    "            else:\n",
    "                image_filenames.append(filenames)\n",
    "\n",
    "    return predictions, uncertainties, image_filenames\n",
    "\n",
    "\n",
    "\n",
    "def perform_sample_selection_dctu_improved(model, pool_image_dir, pool_label_dir, target_image_dir,\n",
    "                                         target_label_dir, selected_samples_dir, samples_per_iteration,\n",
    "                                         device, iteration, val_loader, batch_size=1, alpha=1.0,\n",
    "                                         use_hybrid=True, use_class_constraint=True):\n",
    "    \"\"\"\n",
    "    **IMPROVED DCTU-based Sample Selection with all enhancements**\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Enhanced DCTU-based Sample Selection for Iteration {iteration + 1} ---\")\n",
    "\n",
    "    # Step 1: Compute current class performance gaps (with moderated weighting)\n",
    "    print(\"Computing class performance gaps...\")\n",
    "    class_gaps = compute_class_performance_gaps(model, val_loader, device)\n",
    "\n",
    "    # Step 2: Compute dynamic weights (with regularization and softer weighting)\n",
    "    dynamic_weights = compute_dynamic_weights(class_gaps, alpha,\n",
    "                                            use_softer_weighting=True,\n",
    "                                            regularize=True)\n",
    "\n",
    "    print(\"Enhanced Class Performance Analysis:\")\n",
    "    for i, (gap, weight) in enumerate(zip(class_gaps, dynamic_weights)):\n",
    "        print(f\"  {class_names[i]}: Gap={gap:.4f}, Weight={weight:.4f}\")\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(selected_samples_dir, exist_ok=True)\n",
    "    selected_images_dir = os.path.join(selected_samples_dir, 'images')\n",
    "    selected_labels_dir = os.path.join(selected_samples_dir, 'labels')\n",
    "    os.makedirs(selected_images_dir, exist_ok=True)\n",
    "    os.makedirs(selected_labels_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of available pool samples\n",
    "    pool_files = [f for f in os.listdir(pool_image_dir) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "    print(f\"Available pool samples: {len(pool_files)}\")\n",
    "\n",
    "    if len(pool_files) == 0:\n",
    "        print(\"✗ No samples available in pool!\")\n",
    "        return 0, []\n",
    "\n",
    "    if len(pool_files) < samples_per_iteration:\n",
    "        print(f\"⚠ Only {len(pool_files)} samples available, selecting all\")\n",
    "        samples_per_iteration = len(pool_files)\n",
    "\n",
    "    # Create pool dataset and loader\n",
    "    pool_dataset = ValidationDataset(pool_image_dir, pool_label_dir)\n",
    "    pool_loader = create_safe_dataloader(pool_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Get predictions and uncertainties\n",
    "    print(\"Computing enhanced uncertainties...\")\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    image_filenames = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_loader:\n",
    "            if len(batch) == 3:\n",
    "                images, _, filenames = batch\n",
    "            else:\n",
    "                images, _ = batch\n",
    "                filenames = [f\"batch_image_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Compute uncertainty score for each image in the batch\n",
    "            batch_uncertainty_scores = []\n",
    "            for i in range(probs.size(0)):\n",
    "                if use_hybrid:\n",
    "                    # Use hybrid approach\n",
    "                    uncertainty_score = compute_hybrid_dctu_score(probs[i], dynamic_weights)\n",
    "                else:\n",
    "                    # Use standard DCTU\n",
    "                    uncertainty_score = compute_dctu_score(probs[i], dynamic_weights)\n",
    "                batch_uncertainty_scores.append(uncertainty_score)\n",
    "\n",
    "            uncertainties.extend(batch_uncertainty_scores)\n",
    "\n",
    "            if isinstance(filenames, (list, tuple)):\n",
    "                image_filenames.extend(filenames)\n",
    "            else:\n",
    "                image_filenames.append(filenames)\n",
    "\n",
    "    # Sample selection strategy\n",
    "    if use_class_constraint:\n",
    "        # **CHANGE 3: Use class frequency constraint**\n",
    "        samples_per_class = distribute_samples_by_class(samples_per_iteration, dynamic_weights)\n",
    "        print(f\"Target samples per class: {dict(zip(class_names, samples_per_class))}\")\n",
    "\n",
    "        # For now, fall back to standard selection but this can be enhanced\n",
    "        # to actually enforce per-class selection\n",
    "        uncertainty_pairs = list(zip(uncertainties, image_filenames))\n",
    "        uncertainty_pairs.sort(key=lambda x: x[0].item() if torch.is_tensor(x[0]) else x[0], reverse=True)\n",
    "        selected_files = [filename for _, filename in uncertainty_pairs[:samples_per_iteration]]\n",
    "        selected_uncertainties = [unc for unc, _ in uncertainty_pairs[:samples_per_iteration]]\n",
    "    else:\n",
    "        # Standard uncertainty-based selection\n",
    "        uncertainty_pairs = list(zip(uncertainties, image_filenames))\n",
    "        uncertainty_pairs.sort(key=lambda x: x[0].item() if torch.is_tensor(x[0]) else x[0], reverse=True)\n",
    "        selected_files = [filename for _, filename in uncertainty_pairs[:samples_per_iteration]]\n",
    "        selected_uncertainties = [unc for unc, _ in uncertainty_pairs[:samples_per_iteration]]\n",
    "\n",
    "    print(f\"Top 5 uncertainty scores: {[u.item() if torch.is_tensor(u) else u for u in selected_uncertainties[:5]]}\")\n",
    "\n",
    "    # Move selected samples (rest of the function remains the same as original)\n",
    "    # Get already existing files to avoid duplicates\n",
    "    existing_train_files = set()\n",
    "    if os.path.exists(target_image_dir):\n",
    "        existing_train_files = set([f for f in os.listdir(target_image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    # Move selected samples\n",
    "    moved_count = 0\n",
    "    successfully_moved = []\n",
    "    skipped_files = []\n",
    "    failed_moves = []\n",
    "\n",
    "    selection_log = []  # For tracking selections\n",
    "\n",
    "    for i, filename in enumerate(selected_files):\n",
    "        if filename in existing_train_files:\n",
    "            skipped_files.append(filename)\n",
    "            continue\n",
    "\n",
    "        # Source paths\n",
    "        src_image = os.path.join(pool_image_dir, filename)\n",
    "        src_label = os.path.join(pool_label_dir, filename)\n",
    "\n",
    "        # Destination paths (training)\n",
    "        dst_image = os.path.join(target_image_dir, filename)\n",
    "        dst_label = os.path.join(target_label_dir, filename)\n",
    "\n",
    "        # Selected samples paths (for tracking)\n",
    "        sel_image = os.path.join(selected_images_dir, filename)\n",
    "        sel_label = os.path.join(selected_labels_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Verify source files exist\n",
    "            if not os.path.exists(src_image) or not os.path.exists(src_label):\n",
    "                failed_moves.append(f\"{filename} (missing source)\")\n",
    "                continue\n",
    "\n",
    "            # Copy to selected samples directory (for tracking)\n",
    "            shutil.copy2(src_image, sel_image)\n",
    "            shutil.copy2(src_label, sel_label)\n",
    "\n",
    "            # Move to training directory\n",
    "            shutil.move(src_image, dst_image)\n",
    "            shutil.move(src_label, dst_label)\n",
    "\n",
    "            moved_count += 1\n",
    "            successfully_moved.append(filename)\n",
    "\n",
    "            # Log selection details\n",
    "            uncertainty_score = selected_uncertainties[i]\n",
    "            unc_value = uncertainty_score.item() if torch.is_tensor(uncertainty_score) else uncertainty_score\n",
    "\n",
    "            selection_log.append({\n",
    "                'filename': filename,\n",
    "                'uncertainty_score': unc_value,\n",
    "                'iteration': iteration + 1,\n",
    "                'selection_method': 'Enhanced_DCTU',\n",
    "                'alpha': alpha,\n",
    "                'use_hybrid': use_hybrid,\n",
    "                'use_class_constraint': use_class_constraint\n",
    "            })\n",
    "\n",
    "            print(f\"✓ Moved: {filename} (Uncertainty score: {unc_value:.4f})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_moves.append(f\"{filename} (error: {str(e)})\")\n",
    "            print(f\"✗ Failed to move {filename}: {e}\")\n",
    "\n",
    "    # Save enhanced selection log\n",
    "    if selection_log:\n",
    "        log_df = pd.DataFrame(selection_log)\n",
    "        log_path = os.path.join(selected_samples_dir, f'enhanced_dctu_selection_log_iteration_{iteration + 1}.csv')\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "        print(f\"✓ Enhanced DCTU selection log saved: {log_path}\")\n",
    "\n",
    "        # Also save class analysis\n",
    "        class_analysis = pd.DataFrame({\n",
    "            'class_name': class_names,\n",
    "            'performance_gap': class_gaps,\n",
    "            'dynamic_weight': dynamic_weights\n",
    "        })\n",
    "        class_analysis_path = os.path.join(selected_samples_dir, f'enhanced_class_analysis_iteration_{iteration + 1}.csv')\n",
    "        class_analysis.to_csv(class_analysis_path, index=False)\n",
    "        print(f\"✓ Enhanced class analysis saved: {class_analysis_path}\")\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n--- Enhanced DCTU Selection Summary ---\")\n",
    "    print(f\"Alpha parameter: {alpha}\")\n",
    "    print(f\"Hybrid approach: {use_hybrid}\")\n",
    "    print(f\"Class constraint: {use_class_constraint}\")\n",
    "    print(f\"Requested: {samples_per_iteration}\")\n",
    "    print(f\"Successfully moved: {moved_count}\")\n",
    "    print(f\"Skipped (duplicates): {len(skipped_files)}\")\n",
    "    print(f\"Failed: {len(failed_moves)}\")\n",
    "\n",
    "    # Update pool size\n",
    "    remaining_pool = len([f for f in os.listdir(pool_image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "    print(f\"Remaining in pool: {remaining_pool}\")\n",
    "\n",
    "    return moved_count, successfully_moved\n",
    "def create_test_prediction_heatmaps(model, test_loader, device, save_dir, iteration, class_names):\n",
    "    \"\"\"Create comprehensive test prediction heatmaps and visualizations\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Create subdirectory for test predictions\n",
    "    test_pred_dir = os.path.join(save_dir, 'test_predictions')\n",
    "    os.makedirs(test_pred_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Class-wise confidence distribution\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    class_confidences = [[] for _ in range(len(class_names))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if batch_idx >= 20:  # Limit to first 10 batches\n",
    "                break\n",
    "\n",
    "            if len(batch) == 3:\n",
    "                images, targets, _ = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Collect confidence scores for each class\n",
    "            for cls in range(len(class_names)):\n",
    "                class_prob = probs[:, cls, :, :].cpu().numpy()\n",
    "                class_confidences[cls].extend(class_prob.flatten())\n",
    "\n",
    "    # Plot confidence distributions\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if i < len(axes) and class_confidences[i]:\n",
    "            conf_array = np.array(class_confidences[i])\n",
    "            axes[i].hist(conf_array, bins=50, alpha=0.7, color=plt.cm.tab10(i))\n",
    "            axes[i].set_title(f'{class_name}\\nMean: {conf_array.mean():.3f}', fontweight='bold')\n",
    "            axes[i].set_xlabel('Confidence Score')\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Test Set Class Confidence Distributions - Iteration {iteration}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(test_pred_dir, f'confidence_distributions_iter_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Sample predictions visualization\n",
    "    model.eval()\n",
    "    sample_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            if sample_count >= 20:  # Show 10 samples\n",
    "                break\n",
    "\n",
    "            if len(batch) == 3:\n",
    "                images, targets, filenames = batch\n",
    "            else:\n",
    "                images, targets = batch\n",
    "                filenames = [f\"sample_{batch_idx}_{i}\" for i in range(images.size(0))]\n",
    "\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            for i in range(min(2, images.size(0))):  # Max 2 per batch\n",
    "                if sample_count >= 15:\n",
    "                    break\n",
    "\n",
    "                # Create subplot for this sample\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Original image\n",
    "                img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                axes[0].imshow(img)\n",
    "                axes[0].set_title('Original Image')\n",
    "                axes[0].axis('off')\n",
    "\n",
    "                # Ground truth\n",
    "                gt = targets[i].cpu().numpy()\n",
    "                gt_colored = apply_color_map(gt, COLOR_MAP)\n",
    "                axes[1].imshow(gt_colored)\n",
    "                axes[1].set_title('Ground Truth')\n",
    "                axes[1].axis('off')\n",
    "\n",
    "                # Prediction\n",
    "                pred = predictions[i].cpu().numpy()\n",
    "                pred_colored = apply_color_map(pred, COLOR_MAP)\n",
    "                im2 = axes[2].imshow(pred_colored)\n",
    "                axes[2].set_title('Prediction')\n",
    "                axes[2].axis('off')\n",
    "\n",
    "                # Legend\n",
    "                legend_elements = [Patch(facecolor=np.array(COLOR_MAP[i])/255.0, label=class_names[i]) for i in range(len(class_names))]\n",
    "                fig.legend(handles=legend_elements, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "\n",
    "                filename = filenames[i] if isinstance(filenames[i], str) else f\"sample_{sample_count}\"\n",
    "                plt.suptitle(f'Test Sample: {filename} - Iteration {iteration}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(test_pred_dir, f'sample_{sample_count}_iter_{iteration}.png'),\n",
    "                           dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "                sample_count += 1\n",
    "\n",
    "\n",
    "def verify_data_consistency(image_dir, label_dir, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Verify that images and labels are properly paired\"\"\"\n",
    "    if not os.path.exists(image_dir) or not os.path.exists(label_dir):\n",
    "        print(f\" {dataset_name}: Directories not found\")\n",
    "        return False\n",
    "\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "    label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(('.jpg', '.png', '.tif'))])\n",
    "\n",
    "    print(f\"{dataset_name}: {len(image_files)} images, {len(label_files)} labels\")\n",
    "\n",
    "    if len(image_files) != len(label_files):\n",
    "        print(f\" {dataset_name}: Mismatch in number of images and labels\")\n",
    "        return False\n",
    "\n",
    "    # Check if files match\n",
    "    missing_pairs = []\n",
    "    for img_file in image_files:\n",
    "        if img_file not in label_files:\n",
    "            missing_pairs.append(img_file)\n",
    "\n",
    "    if missing_pairs:\n",
    "        print(f\" {dataset_name}: Missing label files: {missing_pairs[:5]}...\")\n",
    "        return False\n",
    "\n",
    "    print(f\"✓ {dataset_name}: Data consistency verified\")\n",
    "    return True\n",
    "\n",
    "def plot_metrics(metrics_history, save_dir, iteration):\n",
    "    \"\"\"Plot training metrics with improved visualization\"\"\"\n",
    "    if not metrics_history:\n",
    "        return\n",
    "\n",
    "    # Create metrics directory\n",
    "    metrics_dir = os.path.join(save_dir, 'metrics')\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "    # Plot comprehensive metrics\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    iterations = list(range(1, len(metrics_history) + 1))\n",
    "\n",
    "    # Extract metrics\n",
    "    train_losses = [m.get('train_loss', 0) for m in metrics_history]\n",
    "    val_accuracies = [m.get('val_accuracy', 0) for m in metrics_history]\n",
    "    val_losses = [m.get('val_loss', 0) for m in metrics_history]\n",
    "    val_mious = [m.get('val_miou', 0) for m in metrics_history]\n",
    "    samples_added = [m.get('samples_added', 0) for m in metrics_history]\n",
    "    epochs_trained = [m.get('epochs_trained', 0) for m in metrics_history]\n",
    "\n",
    "    # Plot 1: Training Loss\n",
    "    axes[0, 0].plot(iterations, train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[0, 0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Validation Accuracy\n",
    "    axes[0, 1].plot(iterations, val_accuracies, 'g-o', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Validation Loss\n",
    "    axes[0, 2].plot(iterations, val_losses, 'r-o', linewidth=2, markersize=6)\n",
    "    axes[0, 2].set_title('Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('Iteration')\n",
    "    axes[0, 2].set_ylabel('Loss')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 4: Validation mIoU\n",
    "    axes[1, 0].plot(iterations, val_mious, 'purple', marker='o', linewidth=2, markersize=6)\n",
    "    axes[1, 0].set_title('Validation mIoU', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('mIoU')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 5: Samples Added\n",
    "    axes[1, 1].bar(iterations, samples_added, color='orange', alpha=0.7)\n",
    "    axes[1, 1].set_title('Samples Added per Iteration', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Iteration')\n",
    "    axes[1, 1].set_ylabel('Number of Samples')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 6: Epochs Trained\n",
    "    axes[1, 2].bar(iterations, epochs_trained, color='brown', alpha=0.7)\n",
    "    axes[1, 2].set_title('Epochs Trained per Iteration', fontsize=14, fontweight='bold')\n",
    "    axes[1, 2].set_xlabel('Iteration')\n",
    "    axes[1, 2].set_ylabel('Number of Epochs')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Active Learning Progress - Up to Iteration {iteration}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f'metrics_iteration_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Additional plot: Combined accuracy and mIoU\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    ax.plot(iterations, val_accuracies, 'g-o', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "    ax.plot(iterations, val_mious, 'purple', marker='s', label='Validation mIoU', linewidth=2, markersize=6)\n",
    "    ax.set_title('Model Performance Over Iterations', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metrics_dir, f'performance_comparison_iteration_{iteration}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def save_detailed_results(results, save_dir, iteration):\n",
    "    \"\"\"Save detailed results to CSV and create summary report\"\"\"\n",
    "    results_dir = os.path.join(save_dir, 'results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Save detailed metrics\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    metrics_path = os.path.join(results_dir, f'detailed_metrics_iteration_{iteration}.csv')\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "\n",
    "    # Create summary report\n",
    "    summary_path = os.path.join(results_dir, f'summary_report_iteration_{iteration}.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(f\"Active Learning Summary - Iteration {iteration}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        if results:\n",
    "            latest = results[-1]\n",
    "            f.write(f\"Current Performance:\\n\")\n",
    "            f.write(f\"  - Validation Accuracy: {latest.get('val_accuracy', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Validation mIoU: {latest.get('val_miou', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Training Loss: {latest.get('train_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Validation Loss: {latest.get('val_loss', 0):.4f}\\n\")\n",
    "            f.write(f\"  - Samples Added: {latest.get('samples_added', 0)}\\n\")\n",
    "            f.write(f\"  - Epochs Trained: {latest.get('epochs_trained', 0)}\\n\\n\")\n",
    "\n",
    "            # Class-wise performance\n",
    "            if 'class_accuracies' in latest:\n",
    "                f.write(\"Class-wise Accuracies:\\n\")\n",
    "                for i, acc in enumerate(latest['class_accuracies']):\n",
    "                    f.write(f\"  - {class_names[i]}: {acc:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            if 'class_ious' in latest:\n",
    "                f.write(\"Class-wise IoUs:\\n\")\n",
    "                for i, iou in enumerate(latest['class_ious']):\n",
    "                    if not np.isnan(iou):\n",
    "                        f.write(f\"  - {class_names[i]}: {iou:.4f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        # Progress summary\n",
    "        if len(results) > 1:\n",
    "            f.write(\"Progress Summary:\\n\")\n",
    "            first_acc = results[0].get('val_accuracy', 0)\n",
    "            latest_acc = results[-1].get('val_accuracy', 0)\n",
    "            acc_improvement = latest_acc - first_acc\n",
    "\n",
    "            first_miou = results[0].get('val_miou', 0)\n",
    "            latest_miou = results[-1].get('val_miou', 0)\n",
    "            miou_improvement = latest_miou - first_miou\n",
    "\n",
    "            f.write(f\"  - Accuracy Improvement: {acc_improvement:+.4f}\\n\")\n",
    "            f.write(f\"  - mIoU Improvement: {miou_improvement:+.4f}\\n\")\n",
    "\n",
    "            total_samples = sum(r.get('samples_added', 0) for r in results)\n",
    "            f.write(f\"  - Total Samples Added: {total_samples}\\n\")\n",
    "\n",
    "    print(f\"✓ Detailed results saved: {results_dir}\")\n",
    "\n",
    "def calculate_class_weights(train_images_dir, train_labels_dir, num_classes=9):\n",
    "    \"\"\"Calculate class weights based on pixel frequency in training data\"\"\"\n",
    "    print(\"Calculating class weights...\")\n",
    "\n",
    "    class_counts = np.zeros(num_classes)\n",
    "    total_pixels = 0\n",
    "\n",
    "    label_files = [f for f in os.listdir(train_labels_dir) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "\n",
    "    for label_file in label_files:\n",
    "        label_path = os.path.join(train_labels_dir, label_file)\n",
    "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if label is not None:\n",
    "            label = cv2.resize(label, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "            label = np.clip(label, 0, num_classes-1)\n",
    "\n",
    "            # Count pixels for each class\n",
    "            for cls in range(num_classes):\n",
    "                class_counts[cls] += np.sum(label == cls)\n",
    "            total_pixels += label.size\n",
    "\n",
    "    # Calculate weights (inverse frequency)\n",
    "    class_weights = total_pixels / (num_classes * class_counts + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "    # Normalize weights\n",
    "    class_weights = class_weights / class_weights.sum() * num_classes\n",
    "\n",
    "    print(\"Class weights:\")\n",
    "    for i, weight in enumerate(class_weights):\n",
    "        print(f\"  {class_names[i]}: {weight:.4f}\")\n",
    "\n",
    "    return torch.FloatTensor(class_weights)\n",
    "def main():\n",
    "    \"\"\"Main active learning pipeline\"\"\"\n",
    "\n",
    "    # System setup\n",
    "    print(\"ACTIVE LEARNING PIPELINE FOR SEMANTIC SEGMENTATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    global OPTIMAL_WORKERS\n",
    "    OPTIMAL_WORKERS = check_system_capabilities()\n",
    "\n",
    "    # Configure device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "    # Directory setup\n",
    "    BASE_DIR = r\"D:\\DATA\\data\\data\"\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, \"results_dcau2\")\n",
    "\n",
    "    # Data directories\n",
    "    TRAIN_IMAGES = os.path.join(BASE_DIR, \"train_data\" )\n",
    "    TRAIN_LABELS = os.path.join(BASE_DIR, \"train_labels\" )\n",
    "    POOL_IMAGES = os.path.join(BASE_DIR, \"Unlabeled_data\")\n",
    "    POOL_LABELS = os.path.join(BASE_DIR, \"Validation_labels\")\n",
    "    VAL_IMAGES = os.path.join(BASE_DIR, \"val_img\")\n",
    "    VAL_LABELS = os.path.join(BASE_DIR, \"val_lab\")\n",
    "    TEST_IMAGES = os.path.join(BASE_DIR, \"test_img\")\n",
    "    TEST_LABELS = os.path.join(BASE_DIR, \"test_lab\")\n",
    "\n",
    "    # Create directories\n",
    "    for dir_path in [RESULTS_DIR, TRAIN_IMAGES, TRAIN_LABELS, POOL_IMAGES, POOL_LABELS,\n",
    "                     VAL_IMAGES, VAL_LABELS, TEST_IMAGES, TEST_LABELS]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    # Verify data consistency\n",
    "    print(\"\\n--- Data Verification ---\")\n",
    "    train_ok = verify_data_consistency(TRAIN_IMAGES, TRAIN_LABELS, \"Training\")\n",
    "    pool_ok = verify_data_consistency(POOL_IMAGES, POOL_LABELS, \"Pool\")\n",
    "    val_ok = verify_data_consistency(VAL_IMAGES, VAL_LABELS, \"Validation\")\n",
    "    test_ok = verify_data_consistency(TEST_IMAGES, TEST_LABELS, \"Test\")\n",
    "\n",
    "    if not all([train_ok, pool_ok, val_ok, test_ok]):\n",
    "        print(\"Data consistency issues found. Please check your data directories.\")\n",
    "        return\n",
    "\n",
    "    # Active learning parameters\n",
    "    MAX_ITERATIONS = 15\n",
    "    SAMPLES_PER_ITERATION = 25\n",
    "    EPOCHS_PER_ITERATION = 25\n",
    "    epochs_trained = EPOCHS_PER_ITERATION\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 0.0001\n",
    "    # PATIENCE = 20\n",
    "    # MIN_DELTA = 0.001\n",
    "\n",
    "    print(f\"\\n--- Active Learning Configuration ---\")\n",
    "    print(f\"Max Iterations: {MAX_ITERATIONS}\")\n",
    "    print(f\"Samples per Iteration: {SAMPLES_PER_ITERATION}\")\n",
    "    print(f\"Epochs per Iteration: {EPOCHS_PER_ITERATION}\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "#    print(f\"Early Stopping Patience: {PATIENCE}\")\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    metrics_history = []\n",
    "\n",
    "    # Create validation dataset (remains constant)\n",
    "    val_dataset = SegmentationDataset(VAL_IMAGES, VAL_LABELS)\n",
    "    val_loader = create_safe_dataloader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Create test dataset (for evaluation)\n",
    "    test_dataset = ValidationDataset(TEST_IMAGES, TEST_LABELS)\n",
    "    test_loader = create_safe_dataloader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"\\nValidation samples: {len(val_dataset)}\")\n",
    "    print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "    # Active learning loop\n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ACTIVE LEARNING ITERATION {iteration + 1}/{MAX_ITERATIONS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Create iteration directory\n",
    "        iteration_dir = os.path.join(RESULTS_DIR, f\"iteration_{iteration + 1}\")\n",
    "        os.makedirs(iteration_dir, exist_ok=True)\n",
    "\n",
    "        # Check if we have training data\n",
    "        train_files = [f for f in os.listdir(TRAIN_IMAGES) if f.endswith(('.jpg', '.png', '.tif'))]\n",
    "        if len(train_files) == 0:\n",
    "            print(\" No training samples available. Skipping iteration.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Current training samples: {len(train_files)}\")\n",
    "\n",
    "        # Create training dataset and loader\n",
    "        train_dataset = SegmentationDataset(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "        train_loader = create_safe_dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "        # Initialize model\n",
    "        model = UNet(num_classes=num_classes)\n",
    "        print(\"\\n--- Calculating Initial Class Weights ---\")\n",
    "        class_weights = calculate_class_weights(TRAIN_IMAGES, TRAIN_LABELS, num_classes)\n",
    "\n",
    "        class_weights = class_weights.to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "       # criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        # Train model\n",
    "        print(f\"\\n--- Training Model ---\")\n",
    "        start_time = time.time()\n",
    "        model, train_losses, val_accuracies, val_losses, val_mious, epochs_trained = train_model_with_validation(\n",
    "         train_loader, val_loader, model, criterion, optimizer,\n",
    "         EPOCHS_PER_ITERATION, device )\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "        # Save model\n",
    "        model_path = save_model(model, iteration_dir, iteration + 1)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        print(f\"\\n--- Test Evaluation ---\")\n",
    "        test_acc, test_loss, test_miou, test_class_ious, test_class_accuracies = validate_model(\n",
    "            model, test_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Test mIoU: {test_miou:.4f}\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "        # Create test predictions and visualizations\n",
    "        create_test_prediction_heatmaps(model, test_loader, device, iteration_dir, iteration + 1, class_names)\n",
    "\n",
    "        # Store metrics\n",
    "        iteration_metrics = {\n",
    "            'iteration': iteration + 1,\n",
    "            'train_loss': train_losses[-1] if train_losses else 0,\n",
    "            'val_accuracy': val_accuracies[-1] if val_accuracies else 0,\n",
    "            'val_loss': val_losses[-1] if val_losses else 0,\n",
    "            'val_miou': val_mious[-1] if val_mious else 0,\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_miou': test_miou,\n",
    "            'epochs_trained': epochs_trained,\n",
    "            'class_accuracies': test_class_accuracies,\n",
    "            'class_ious': test_class_ious.tolist() if hasattr(test_class_ious, 'tolist') else test_class_ious,\n",
    "            'class_weights': class_weights.cpu().tolist(),\n",
    "            'samples_added': 0  # Will be updated after sample selection\n",
    "        }\n",
    "\n",
    "        # Sample selection for next iteration (if not last iteration)\n",
    "        if iteration < MAX_ITERATIONS - 1:\n",
    "            print(f\"\\n--- Sample Selection ---\")\n",
    "            selected_samples_dir = os.path.join(iteration_dir, \"selected_samples\")\n",
    "\n",
    "            samples_added, selected_files = perform_sample_selection_dctu_improved(\n",
    "                model, POOL_IMAGES, POOL_LABELS, TRAIN_IMAGES, TRAIN_LABELS,\n",
    "                selected_samples_dir, SAMPLES_PER_ITERATION, device, iteration, val_loader, BATCH_SIZE\n",
    "            )\n",
    "\n",
    "            iteration_metrics['samples_added'] = samples_added\n",
    "\n",
    "            if samples_added == 0:\n",
    "                print(\" No samples could be added. Stopping active learning.\")\n",
    "                break\n",
    "\n",
    "        metrics_history.append(iteration_metrics)\n",
    "\n",
    "        # Plot and save results\n",
    "        plot_metrics(metrics_history, RESULTS_DIR, iteration + 1)\n",
    "        save_detailed_results(metrics_history, RESULTS_DIR, iteration + 1)\n",
    "\n",
    "        # Memory cleanup\n",
    "        del model, train_loader, train_dataset\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"\\n--- Iteration {iteration + 1} Complete ---\")\n",
    "        print(f\"Training samples: {len(train_files)}\")\n",
    "        print(f\"Validation Accuracy: {iteration_metrics['val_accuracy']:.4f}\")\n",
    "        print(f\"Test Accuracy: {iteration_metrics['test_accuracy']:.4f}\")\n",
    "        print(f\"Test mIoU: {iteration_metrics['test_miou']:.4f}\")\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ACTIVE LEARNING COMPLETED\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if metrics_history:\n",
    "        print(f\"Total iterations: {len(metrics_history)}\")\n",
    "        print(f\"Final test accuracy: {metrics_history[-1]['test_accuracy']:.4f}\")\n",
    "        print(f\"Final test mIoU: {metrics_history[-1]['test_miou']:.4f}\")\n",
    "\n",
    "        # Calculate improvement\n",
    "        if len(metrics_history) > 1:\n",
    "            acc_improvement = metrics_history[-1]['test_accuracy'] - metrics_history[0]['test_accuracy']\n",
    "            miou_improvement = metrics_history[-1]['test_miou'] - metrics_history[0]['test_miou']\n",
    "            print(f\"Accuracy improvement: {acc_improvement:+.4f}\")\n",
    "            print(f\"mIoU improvement: {miou_improvement:+.4f}\")\n",
    "\n",
    "    print(f\"\\nResults saved in: {RESULTS_DIR}\")\n",
    "    print(\"Active learning pipeline completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c599e-cd45-425c-825f-f3d4a1508f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
